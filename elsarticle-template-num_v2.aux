\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\emailauthor{halimnoor@usm.my}{Mohd Halim Mohd Noor \corref {cor1}}
\emailauthor{ayo.ige@aaua.edu.ng}{Ayokunle Olalekan Ige}
\Newlabel{cor1}{1}
\babel@aux{english}{}
\Newlabel{1}{a}
\Newlabel{2}{b}
\citation{shamshirband_review_2021}
\citation{wang_deep_2018}
\citation{pierson_deep_2017}
\citation{dixit_deep_2021}
\citation{noauthor_alphafold_2025}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{sec1}{{1}{2}{Introduction}{section.1}{}}
\citation{dong_survey_2021}
\citation{talaei_khoei_deep_2023}
\citation{alzubaidi_review_2021}
\citation{alom_state_art_2019}
\citation{pouyanfar_survey_2018}
\citation{sarker_deep_2021}
\citation{dong_survey_2021}
\citation{talaei_khoei_deep_2023}
\citation{alzubaidi_review_2021}
\citation{alom_state_art_2019}
\citation{pouyanfar_survey_2018}
\citation{sarker_deep_2021}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of related works.}}{5}{table.1}\protected@file@percent }
\newlabel{table_summary_related_works}{{1}{5}{Summary of related works}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Fundamentals of Deep Learning}{6}{section.2}\protected@file@percent }
\newlabel{sec2}{{2}{6}{Fundamentals of Deep Learning}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Layers}{6}{subsection.2.1}\protected@file@percent }
\citation{lecun_deep_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A graphical representation of a neuron.}}{7}{figure.1}\protected@file@percent }
\newlabel{fig_layers_neuron}{{1}{7}{A graphical representation of a neuron}{figure.1}{}}
\citation{noauthor_poloclubcnn-explainer_2025}
\citation{lecun_deep_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A neuron is connected to a local region of the input data.}}{8}{figure.2}\protected@file@percent }
\newlabel{fig_layers_convolution}{{2}{8}{A neuron is connected to a local region of the input data}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Summaries of the feature map using maximum or average pooling to produce a reduced feature map.}}{9}{figure.3}\protected@file@percent }
\newlabel{fig_layers_pooling}{{3}{9}{Summaries of the feature map using maximum or average pooling to produce a reduced feature map}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Attention Mechanisms}{9}{subsection.2.2}\protected@file@percent }
\citation{hu_squeeze-and-excitation_2019}
\citation{gao_global_2018}
\citation{wang_eca-net_2020}
\citation{liu_tam_2021}
\citation{vaswani_attention_2023}
\citation{noauthor_poloclubtransformer-explainer_2025}
\citation{oktay_attention_2018}
\citation{dosovitskiy_image_2021}
\citation{guo_beyond_2023}
\citation{lecun_efficient_2012}
\citation{hochreiter_gradient_2001}
\citation{dugas_incorporating_2000}
\citation{glorot_deep_2011}
\citation{maas_rectifier_2013}
\citation{misra_mish_2020}
\citation{clevert_fast_2016}
\citation{wang_comprehensive_2022}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Activation Functions}{12}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Parameter Learning and Loss Functions}{12}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sigmoid activation function.}}{13}{figure.4}\protected@file@percent }
\newlabel{fig_activation_functions_sigmoid}{{4}{13}{Sigmoid activation function}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Hyperbolic tangent activation function.}}{13}{figure.5}\protected@file@percent }
\newlabel{fig_activation_functions_tanh}{{5}{13}{Hyperbolic tangent activation function}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Rectified linear unit activation function.}}{13}{figure.6}\protected@file@percent }
\newlabel{fig_activation_functions_relu}{{6}{13}{Rectified linear unit activation function}{figure.6}{}}
\citation{carter_tensorflow_nodate}
\citation{guo_ai_nodate}
\citation{qian_momentum_1999}
\citation{duchi_adaptive_2011}
\citation{kingma_adam_2017}
\citation{prechelt_early_2012}
\citation{srivastava_dropout_2014}
\citation{srivastava_dropout_2014}
\citation{park_analysis_2017}
\citation{liu_dropout_2023}
\citation{tibshirani_regression_1996}
\citation{zou_regularization_2005}
\citation{nakamura_adaptive_2019}
\citation{ioffe_batch_2015}
\citation{ba_layer_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Regularization Methods}{15}{subsection.2.5}\protected@file@percent }
\citation{cybenko_approximation_1989}
\citation{hornik_multilayer_1989}
\citation{widrow_neural_1994}
\citation{hochreiter_long_1997}
\citation{cho_learning_2014}
\citation{shi_convolutional_2015}
\@writefile{toc}{\contentsline {section}{\numberline {3}Types of Deep Learning}{16}{section.3}\protected@file@percent }
\newlabel{sec3}{{3}{16}{Types of Deep Learning}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Deep Supervised Learning}{16}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Multilayer Perceptron}{16}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Recurrent Neural Network}{16}{subsubsection.3.1.2}\protected@file@percent }
\citation{van_houdt_review_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A fully connected neural network.}}{17}{figure.7}\protected@file@percent }
\newlabel{fig_deep_sv_learning_mlp}{{7}{17}{A fully connected neural network}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A neural network with recurrent connection.}}{18}{figure.8}\protected@file@percent }
\newlabel{fig_deep_sv_learning_rnn}{{8}{18}{A neural network with recurrent connection}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Convolutional Neural Network}{18}{subsubsection.3.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The architecture of an LSTM unit.}}{19}{figure.9}\protected@file@percent }
\newlabel{fig_deep_sv_learning_lstm}{{9}{19}{The architecture of an LSTM unit}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The architecture of an LSTM unit.}}{19}{figure.10}\protected@file@percent }
\newlabel{fig_deep_sv_learning_gru}{{10}{19}{The architecture of an LSTM unit}{figure.10}{}}
\citation{krizhevsky_imagenet_2012}
\citation{zeiler_visualizing_2013}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A neural network with convolutional and pooling layers followed by fully connected layers.}}{20}{figure.11}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn}{{11}{20}{A neural network with convolutional and pooling layers followed by fully connected layers}{figure.11}{}}
\citation{lin_network_2014}
\citation{simonyan_very_2015}
\citation{szegedy_going_2014}
\citation{szegedy_going_2014}
\citation{srivastava_highway_2015}
\citation{he_deep_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The inception module. Adapted from \citep  {szegedy_going_2014}.}}{22}{figure.12}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_inception}{{12}{22}{The inception module. Adapted from \citep {szegedy_going_2014}}{figure.12}{}}
\citation{he_deep_2015}
\citation{he_deep_2015}
\citation{huang_densely_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A residual connection which explicitly incorporates features from previous layers into the later layers. Adapted from \citep  {he_deep_2015}.}}{23}{figure.13}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_resnet}{{13}{23}{A residual connection which explicitly incorporates features from previous layers into the later layers. Adapted from \citep {he_deep_2015}}{figure.13}{}}
\citation{huang_densely_2017}
\citation{zagoruyko_wide_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces A 5-layer dense block. Adapted from \citep  {huang_densely_2017}}}{24}{figure.14}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_densenet}{{14}{24}{A 5-layer dense block. Adapted from \citep {huang_densely_2017}}{figure.14}{}}
\citation{xie_aggregated_2017}
\citation{xie_aggregated_2017}
\citation{noauthor_imagenet_nodate}
\citation{noauthor_cifar-10_nodate}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces A cardinal block. Adapted from \citep  {xie_aggregated_2017}}}{25}{figure.15}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_resnext}{{15}{25}{A cardinal block. Adapted from \citep {xie_aggregated_2017}}{figure.15}{}}
\citation{chougrad_deep_2018}
\citation{zhao_novel_2020}
\citation{cinar_hybrid_2022}
\citation{sun_self-attentional_2023}
\citation{dong_improved_2023}
\citation{hou_application_2024}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Applications of Deep Supervised Learning Models}{26}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Top five classification errors on ImageNet.}}{27}{figure.16}\protected@file@percent }
\newlabel{fig_cnn_top_five_errors_imagenet}{{16}{27}{Top five classification errors on ImageNet}{figure.16}{}}
\citation{narotamo_deep_2024}
\citation{zhang_heart_2024}
\citation{mohd_noor_deep_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Top one classification errors on CIFAR-10.}}{28}{figure.17}\protected@file@percent }
\newlabel{fig_cnn_top_one_errors_cifar10}{{17}{28}{Top one classification errors on CIFAR-10}{figure.17}{}}
\citation{hinton_practical_2012}
\citation{hinton_fast_2006}
\citation{hinton_deep_2009}
\citation{romero_quantum_2017}
\citation{li_guided_2020}
\citation{mohd_noor_feature_2021}
\citation{li_comprehensive_2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Deep Unsupervised Learning}{29}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces A restricted Boltzmann machine.}}{30}{figure.18}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_rbm}{{18}{30}{A restricted Boltzmann machine}{figure.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces A deep belief network.}}{30}{figure.19}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_dbn}{{19}{30}{A deep belief network}{figure.19}{}}
\citation{ng_sparse_2011}
\citation{rifai_higher_2011}
\citation{vincent_extracting_2008}
\citation{chen_marginalized_2012}
\citation{kingma_auto-encoding_2013}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces An autoencoder.}}{31}{figure.20}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_ae}{{20}{31}{An autoencoder}{figure.20}{}}
\citation{goodfellow_generative_2014}
\citation{odena_conditional_2017}
\citation{chen_infogan_2016}
\citation{weng_gan_2019}
\citation{karras_progressive_2018}
\citation{karras_style-based_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces A generative adversarial network.}}{32}{figure.21}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_gan}{{21}{32}{A generative adversarial network}{figure.21}{}}
\citation{Tan_2020_CVPR}
\citation{Otter}
\citation{esteva2019guide}
\citation{soori2023artificial}
\citation{hernandez2019systematic}
\citation{lecun_gradient-based_1998}
\citation{simard_best_2003,matsugu_subject_2003}
\citation{krizhevsky_imagenet_2012}
\@writefile{toc}{\contentsline {section}{\numberline {4}State-of-the-art Deep Learning Applications}{33}{section.4}\protected@file@percent }
\newlabel{sec4}{{4}{33}{State-of-the-art Deep Learning Applications}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Computer Vision}{33}{subsection.4.1}\protected@file@percent }
\citation{zhao_well-classified_2022}
\citation{huang_asymmetric_2023}
\citation{park_robust_2023}
\citation{nanni_building_2023}
\citation{wortsman_model_2022}
\citation{loh_multi-symmetry_2023}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Image Classification}{34}{subsubsection.4.1.1}\protected@file@percent }
\citation{xiao_early_2021}
\citation{wu_cvt_2021}
\citation{peng_conformer_2023}
\citation{tu_maxvit_2022}
\citation{ma_convolutional_2024}
\citation{tu_maxvit_2022}
\citation{zhao_well-classified_2022}
\citation{huang_asymmetric_2023}
\citation{park_robust_2023}
\citation{peng_conformer_2023}
\citation{tu_maxvit_2022}
\citation{ma_convolutional_2024}
\citation{girshick_rich_2014}
\citation{girshick_fast_2015}
\citation{ren_faster_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces The architecture of MaxViT \citep  {tu_maxvit_2022}.}}{36}{figure.22}\protected@file@percent }
\newlabel{fig_img_clf_MaxViT}{{22}{36}{The architecture of MaxViT \citep {tu_maxvit_2022}}{figure.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Object Detection}{36}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of state-of-the-art image classification.}}{37}{table.2}\protected@file@percent }
\newlabel{table_summary_imgclf_studies}{{2}{37}{Summary of state-of-the-art image classification}{table.2}{}}
\citation{redmon_you_2016}
\citation{redmon_yolov3_2018}
\citation{bochkovskiy_yolov4_2020}
\citation{liu_ssd_2016}
\citation{lin_focal_2020}
\citation{lin_feature_2017}
\citation{tan_efficientdet_2020}
\citation{tan_efficientnet_2019}
\citation{bodla_soft-nmsimproving_2017}
\citation{liu_adaptive_2019}
\citation{husham_al-badri_adaptive_2023}
\citation{jiang_non-maximum_2024}
\citation{shi_similarity_2024}
\citation{carion_end_end_2020}
\citation{zhu_deformable_2020}
\citation{dai_dynamic_2021}
\citation{jia_detrs_2023}
\citation{huang_teach-detr_2023}
\citation{dai_dynamic_2021}
\citation{husham_al-badri_adaptive_2023}
\citation{jiang_non-maximum_2024}
\citation{shi_similarity_2024}
\citation{dai_dynamic_2021}
\citation{jia_detrs_2023}
\citation{huang_teach-detr_2023}
\citation{long_fully_2015}
\citation{noh_learning_2015}
\citation{badrinarayanan_segnet_2017}
\citation{chaurasia_linknet_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces The architecture of dynamic DeTR \citep  {dai_dynamic_2021}.}}{41}{figure.23}\protected@file@percent }
\newlabel{fig_obj_det_Dynamic-DETR}{{23}{41}{The architecture of dynamic DeTR \citep {dai_dynamic_2021}}{figure.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Image Segmentation}{41}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Summary of state-of-the-art object detection.}}{42}{table.3}\protected@file@percent }
\newlabel{table_summary_objdet_studies}{{3}{42}{Summary of state-of-the-art object detection}{table.3}{}}
\citation{he_mask_2017}
\citation{liu_path_2018}
\citation{chen_masklab_2018}
\citation{liu_multi-stage_2023}
\citation{liu_covariance_2022}
\citation{strudel_segmenter_2021}
\citation{hatamizadeh_global_2023}
\citation{shi_transformer_2023}
\citation{hatamizadeh_global_2023}
\citation{liu_multi-stage_2023}
\citation{liu_covariance_2022}
\citation{strudel_segmenter_2021}
\citation{hatamizadeh_global_2023}
\citation{shi_transformer_2023}
\citation{kingma_auto-encoding_2013}
\citation{goodfellow_generative_2014}
\citation{odena_conditional_2017}
\citation{radford_unsupervised_2015}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Summary of state-of-the-art image segmentation.}}{45}{table.4}\protected@file@percent }
\newlabel{table_summary_imgseg_studies}{{4}{45}{Summary of state-of-the-art image segmentation}{table.4}{}}
\citation{zhang_stackgan_2017}
\citation{zhang_stackgan_2018}
\citation{zhang_photographic_2018}
\citation{zhu_dm-gan_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces The architecture of global context ViT \citep  {hatamizadeh_global_2023}.}}{46}{figure.24}\protected@file@percent }
\newlabel{fig_img_seg_GC-ViT}{{24}{46}{The architecture of global context ViT \citep {hatamizadeh_global_2023}}{figure.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Image Generation}{46}{subsubsection.4.1.4}\protected@file@percent }
\citation{xu_attngan_2018}
\citation{sun_resfpa-gan_2019}
\citation{cai_dualattn-gan_2019}
\citation{xu_attngan_2018}
\citation{tao_df-gan_2022}
\citation{yang_dmf-gan_2024}
\citation{jiang_-gan_2024}
\citation{yang_dmf-gan_2024}
\citation{tao_df-gan_2022}
\citation{yang_dmf-gan_2024}
\citation{jiang_-gan_2024}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces The architecture of AttnGAN \citep  {xu_attngan_2018}.}}{48}{figure.25}\protected@file@percent }
\newlabel{fig_image_gen_AttnGAN}{{25}{48}{The architecture of AttnGAN \citep {xu_attngan_2018}}{figure.25}{}}
\citation{calvo_intelligent_2000,yu_latent_2008}
\citation{arevian_recurrent_2007}
\citation{huang_optimization_2020}
\citation{wang_convolutional_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces The architecture of DMF-GAN \citep  {yang_dmf-gan_2024}.}}{49}{figure.26}\protected@file@percent }
\newlabel{fig_image_gen_DMF-GAN}{{26}{49}{The architecture of DMF-GAN \citep {yang_dmf-gan_2024}}{figure.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Summary of state-of-the-art image generation.}}{49}{table.5}\protected@file@percent }
\newlabel{table_summary_imggen_studies}{{5}{49}{Summary of state-of-the-art image generation}{table.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Natural Language Processing}{49}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Text Classification}{49}{subsubsection.4.2.1}\protected@file@percent }
\citation{liu_bidirectional_2019}
\citation{lin_structured_2017}
\citation{li_bidirectional_2020}
\citation{devlin_bert_2018}
\citation{lan_albert_2019}
\citation{liu_roberta_2019}
\citation{he_deberta_2020}
\citation{rodrawangpai_improving_2022}
\citation{murfi_bert-based_2024}
\citation{hao_sentiment_2023}
\citation{wang_joint_2018}
\citation{yan_r-transformer_bilstm_2023}
\citation{zhu_bert-based_2023}
\citation{zhu_bert-based_2023}
\citation{rodrawangpai_improving_2022}
\citation{murfi_bert-based_2024}
\citation{hao_sentiment_2023}
\citation{yan_r-transformer_bilstm_2023}
\citation{zhu_bert-based_2023}
\citation{cho_learning_2014,sutskever_sequence_2014}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Neural Machine Translation}{52}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Summary of state-of-the-art text classification.}}{53}{table.6}\protected@file@percent }
\newlabel{table_summary_textclf_studies}{{6}{53}{Summary of state-of-the-art text classification}{table.6}{}}
\citation{stahlberg_neural_2020}
\citation{bahdanau_neural_2014}
\citation{bahdanau_neural_2014}
\citation{luong_effective_2015}
\citation{vaswani_attention_2023}
\citation{luong_effective_2015}
\citation{wu_googles_2016}
\citation{vaswani_attention_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces The architecture of BERT-MSL \citep  {zhu_bert-based_2023}.}}{54}{figure.27}\protected@file@percent }
\newlabel{fig_text_clf_BERT-MSL}{{27}{54}{The architecture of BERT-MSL \citep {zhu_bert-based_2023}}{figure.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces The architecture of an encoder-decoder. Adapted from \citep  {stahlberg_neural_2020}.}}{54}{figure.28}\protected@file@percent }
\newlabel{fig_nmt_encoder_decoder}{{28}{54}{The architecture of an encoder-decoder. Adapted from \citep {stahlberg_neural_2020}}{figure.28}{}}
\citation{wu_googles_2016}
\citation{lupo_encoding_2023}
\citation{rippeth_improving_2023}
\citation{wu_study_2022}
\citation{kim_towards_2023}
\citation{gezmu_transformers_2022}
\citation{araabi_optimizing_2020}
\citation{meetei_cues_2023}
\citation{faheem_improving_2024}
\citation{li_towards_2024}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces The architecture of Google Neural Machine Translation \citep  {wu_googles_2016}.}}{56}{figure.29}\protected@file@percent }
\newlabel{fig_nmt_GNMT}{{29}{56}{The architecture of Google Neural Machine Translation \citep {wu_googles_2016}}{figure.29}{}}
\citation{lupo_encoding_2023}
\citation{rippeth_improving_2023}
\citation{wu_study_2022}
\citation{kim_towards_2023}
\citation{faheem_improving_2024}
\citation{li_towards_2024}
\citation{nie_attention-based_2017}
\citation{yin_neural_2015}
\citation{li_deep_2016}
\citation{wu_building_2020}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Text Generation}{57}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Summary of state-of-the-art neural machine translation.}}{58}{table.7}\protected@file@percent }
\newlabel{table_summary_nmt_studies}{{7}{58}{Summary of state-of-the-art neural machine translation}{table.7}{}}
\citation{li_incremental_2019}
\citation{alrowili_biom-transformers_2021}
\citation{alrowili_exploring_2022}
\citation{ma_t-bertsum_2021}
\citation{li_feature-aware_2023}
\citation{kwon_class_2024}
\citation{xie_pre-trained_2022}
\citation{hajipoor_gptgan_2025}
\citation{ma_t-bertsum_2021}
\citation{li_feature-aware_2023}
\citation{kwon_class_2024}
\citation{xie_pre-trained_2022}
\citation{hajipoor_gptgan_2025}
\citation{weiser1991computer}
\citation{he2020developing}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Time Series and Pervasive Computing}{60}{subsection.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Summary of state-of-the-art text generation.}}{61}{table.8}\protected@file@percent }
\newlabel{table_summary_textgen_studies}{{8}{61}{Summary of state-of-the-art text generation}{table.8}{}}
\citation{ige2022survey}
\citation{mohd_noor_feature_2021}
\citation{singh2017stock}
\citation{zhang2021hoba}
\citation{lei2020deep}
\citation{zhang2019comprehensive}
\citation{ige2022survey}
\citation{dang2020sensor}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Human Activity Recognition}{62}{subsubsection.4.3.1}\protected@file@percent }
\citation{gao2021danhar}
\citation{gupta2021deep}
\citation{erdacs2021human}
\citation{mohd_noor_feature_2021}
\citation{ragab2020random}
\citation{banjarey2022human}
\citation{baraka_similarity_2023}
\citation{baraka_deep_2024}
\citation{shuvo2020hybrid}
\citation{han2022human}
\citation{ige2023wsense}
\citation{deep_hybrid_2019}
\citation{luwe_wearable_2022,shi_novel_2023}
\citation{dua_inception_2023}
\citation{imran_smart-wearable_2024}
\citation{nafea_sensor-based_2021}
\citation{khan_attention_2021}
\citation{ige_deep_2023}
\citation{gao_danhar_2021}
\citation{agac_resource-efficient_2024}
\citation{tang_triple_2022}
\citation{misra_rotate_2020}
\citation{khan_attention_2021}
\citation{chen_transformer_2022}
\citation{sun_efficient_2024}
\citation{lattanzi_are_2025}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces The architecture of multi-head CNN model \citep  {khan_attention_2021}.}}{66}{figure.30}\protected@file@percent }
\newlabel{fig_har_multi-head_cnn}{{30}{66}{The architecture of multi-head CNN model \citep {khan_attention_2021}}{figure.30}{}}
\citation{chan_unified_2021}
\citation{jimale_fully_2022}
\citation{lupion_data_2024}
\citation{kia_human_2024}
\citation{mohammadzadeh_cgan-based_2025}
\citation{dua_inception_2023}
\citation{ige_deep_2023}
\citation{agac_resource-efficient_2024}
\citation{sun_efficient_2024}
\citation{lupion_data_2024}
\citation{kia_human_2024}
\citation{mohammadzadeh_cgan-based_2025}
\citation{Nassif2019}
\citation{Tirumala,app11083603}
\citation{khalil2019}
\citation{singh2021spoken}
\citation{jiao2016accent}
\citation{sanchez2022age}
\citation{alnuaim2022speaker}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Summary of state-of-the-art human activity recognition.}}{68}{table.9}\protected@file@percent }
\newlabel{table_summary_har_studies}{{9}{68}{Summary of state-of-the-art human activity recognition}{table.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Speech Recognition}{68}{subsubsection.4.3.2}\protected@file@percent }
\citation{srivastava2022speech}
\citation{padmanabhan2015review,Nassif2019}
\citation{mukhamadiyev2022automatic}
\citation{lu2020automatic}
\citation{HEMA2023109492}
\citation{shewalkar2019performance}
\citation{prabhavalkar2017comparison}
\citation{graves2012sequence}
\citation{chan2015listen}
\citation{jaitly2016online}
\citation{raffel2017online}
\citation{sak2017recurrent}
\citation{szucbeamsearch2019,li2018seq2seq}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Sequence-to-Sequence}}{71}{figure.31}\protected@file@percent }
\newlabel{fig_speech_seq2seq}{{31}{71}{Sequence-to-Sequence}{figure.31}{}}
\citation{chiugoogle}
\citation{prabhavalkar2017comparison}
\citation{baevski_wav2vec_2020}
\citation{radford_robust_2022}
\citation{gulati_conformer_2020}
\citation{stooke_aligner-encoders_2025}
\citation{zhang_breaking_2025}
\citation{wang_disentangled-transformer_2024}
\citation{shakhadri_samba-asr_2025}
\citation{radford_robust_2022}
\citation{stooke_aligner-encoders_2025}
\citation{zhang_breaking_2025}
\citation{wang_disentangled-transformer_2024}
\citation{shakhadri_samba-asr_2025}
\citation{ozbayoglu2020deep}
\citation{singh2017stock}
\citation{lei2020deep}
\citation{shen2021new}
\citation{wang2020portfolio}
\citation{chen2024deep}
\citation{ahnouch2023model}
\citation{SUN2020101160}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Summary of state-of-the-art speech recognition.}}{74}{table.10}\protected@file@percent }
\newlabel{table_summary_speech_studies}{{10}{74}{Summary of state-of-the-art speech recognition}{table.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Finance}{74}{subsubsection.4.3.3}\protected@file@percent }
\citation{abedin2021deep}
\citation{wang_sudf-rs_2023}
\citation{nikou2019stock}
\citation{cai2018financial}
\citation{gudelek2017deep}
\citation{eapen2019novel}
\citation{chen_deep_2024}
\citation{mozaffari_predictive_2024}
\citation{li_transformer_2025}
\citation{zhou_informer_2021}
\citation{berti_tlob_2025}
\citation{wang_sudf-rs_2023}
\citation{chen_deep_2024}
\citation{mozaffari_predictive_2024}
\citation{li_transformer_2025}
\citation{berti_tlob_2025}
\citation{LIU2021107187}
\citation{tsao2023heart}
\citation{LIU2021107187}
\citation{LLamedo2011}
\citation{MATHEWS201853}
\citation{zhu2019}
\citation{desai2021low}
\citation{crippa2015multi}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Summary of state-of-the-art finance applications.}}{77}{table.11}\protected@file@percent }
\newlabel{table_summary_finance_studies}{{11}{77}{Summary of state-of-the-art finance applications}{table.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Electrocardiogram (ECG) Classification}{77}{subsubsection.4.3.4}\protected@file@percent }
\citation{acharya2017deep}
\citation{baloglu2019classification}
\citation{singh2018classification}
\citation{prabhakararao2020attentive}
\citation{wang2023single}
\citation{sowmya2022contemplate}
\citation{rai2022hybrid}
\citation{Banerjee2020}
\citation{kusuma_ecg_2022}
\citation{alamatsaz_lightweight_2024}
\citation{chen_automated_2022}
\citation{wang_automated_2021}
\citation{zhang_ecg-based_2020}
\citation{sun_arrhythmia_2024}
\citation{huang_ecg_2024}
\citation{aghaomidi_ecg-sleepnet_2024}
\citation{hasani_liquid_2021}
\citation{zhu_electrocardiogram_2019}
\citation{yang_data_2024}
\citation{msigwa_iot-driven_2024}
\citation{yang_data_2024}
\citation{sun_arrhythmia_2024}
\citation{alamatsaz_lightweight_2024}
\citation{chen_automated_2022}
\citation{huang_ecg_2024}
\citation{aghaomidi_ecg-sleepnet_2024}
\citation{yang_data_2024}
\citation{msigwa_iot-driven_2024}
\citation{Schirrmeister2017}
\citation{gao2021complex}
\citation{Schirrmeister2017}
\citation{Ang7802578}
\citation{shen2022aberrated}
\citation{boonyaki2020}
\citation{sharma2021automated,vaquerizo2023explainable}
\citation{modir2023systematic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.5}Electroencephalography (EEG) Classification}{81}{subsubsection.4.3.5}\protected@file@percent }
\citation{altaheri2023deep}
\citation{brunner2007spatial,delorme2007enhanced,jafarifarmand2019eeg}
\citation{zhang2019novel}
\citation{kumar2016deep}
\citation{tibrewal2022}
\citation{Schirrmeister2017}
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces The architecture of CECG-GAN \citep  {yang_data_2024}.}}{82}{figure.32}\protected@file@percent }
\newlabel{fig_ecg_gan_ae}{{32}{82}{The architecture of CECG-GAN \citep {yang_data_2024}}{figure.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Summary of state-of-the-art ECG classification.}}{83}{table.12}\protected@file@percent }
\newlabel{table_summary_ecg_studies}{{12}{83}{Summary of state-of-the-art ECG classification}{table.12}{}}
\citation{dai2019eeg}
\citation{LiMingaiLSTM}
\citation{Feng2020novel}
\citation{hwang_improving_2023}
\citation{zhao_deep_2015}
\citation{xia_novel_2023}
\citation{hermawan_multi_2024}
\citation{abdulwahhab_detection_2024}
\citation{pandey_subject_2022}
\citation{hassouneh_development_2020}
\citation{pan_multimodal_2024}
\citation{wang_multimodal_2023}
\citation{pan_multimodal_2024}
\citation{wang_multimodal_2023}
\citation{song_eeggan-net_2024}
\citation{corley_deep_2025}
\citation{cai_dhct-gan_2025}
\citation{hermawan_multi_2024}
\citation{pan_multimodal_2024}
\citation{wang_multimodal_2023}
\citation{abdulwahhab_detection_2024}
\citation{song_eeggan-net_2024}
\citation{corley_deep_2025}
\citation{cai_dhct-gan_2025}
\citation{le_application_2025}
\citation{vukicevic_versatile_2025}
\citation{kirillov_segment_2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Robotics}{86}{subsection.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Summary of state-of-the-art EEG classification.}}{87}{table.13}\protected@file@percent }
\newlabel{table_summary_eeg_studies}{{13}{87}{Summary of state-of-the-art EEG classification}{table.13}{}}
\citation{liu_automatic_2025}
\citation{ge_deep_2025}
\citation{dai_advanced_2024}
\citation{le_application_2025}
\citation{vukicevic_versatile_2025}
\citation{kirillov_segment_2023}
\citation{ge_deep_2025}
\citation{dai_advanced_2024}
\citation{alotaibi_deep_2024}
\citation{misir_drivable_2024}
\citation{chen_rethinking_2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Object Identification}{88}{subsubsection.4.4.1}\protected@file@percent }
\citation{cao_orchard_2024}
\citation{liu_single-stage_2025}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Summary of state-of-the-art robot object identification.}}{89}{table.14}\protected@file@percent }
\newlabel{table_summary_objidn_studies}{{14}{89}{Summary of state-of-the-art robot object identification}{table.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Path Extraction and Navigation}{89}{subsubsection.4.4.2}\protected@file@percent }
\citation{alotaibi_deep_2024}
\citation{misir_drivable_2024}
\citation{cao_orchard_2024}
\citation{liu_single-stage_2025}
\citation{huang_survey_2025}
\citation{asuzu_humanrobot_2025}
\citation{chen_synergai_2024}
\@writefile{lot}{\contentsline {table}{\numberline {15}{\ignorespaces Summary of state-of-the-art path extraction and navigation.}}{90}{table.15}\protected@file@percent }
\newlabel{table_summary_nav_studies}{{15}{90}{Summary of state-of-the-art path extraction and navigation}{table.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Human-Robot Interaction}{90}{subsubsection.4.4.3}\protected@file@percent }
\citation{allgeuer_when_2024}
\citation{wang_i_2024}
\citation{allgeuer_when_2024}
\citation{asuzu_humanrobot_2025}
\citation{chen_synergai_2024}
\citation{allgeuer_when_2024}
\citation{wang_i_2024}
\@writefile{toc}{\contentsline {section}{\numberline {5}Research Challenges}{91}{section.5}\protected@file@percent }
\newlabel{sec5}{{5}{91}{Research Challenges}{section.5}{}}
\citation{tonekaboni_what_2019}
\citation{tjoa_enhancing_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces A grounded chat architecture \citep  {allgeuer_when_2024}.}}{92}{figure.33}\protected@file@percent }
\newlabel{fig_grounded_chat_architecture}{{33}{92}{A grounded chat architecture \citep {allgeuer_when_2024}}{figure.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {16}{\ignorespaces Summary of state-of-the-art human-robot interaction.}}{92}{table.16}\protected@file@percent }
\newlabel{table_summary_hri_studies}{{16}{92}{Summary of state-of-the-art human-robot interaction}{table.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Ethical Issues}{92}{subsection.5.1}\protected@file@percent }
\citation{li_hybrid_2024}
\citation{termritthikun_explainable_2023}
\citation{xiong_explainable_2022}
\citation{fernandes_intrinsic_2023}
\citation{freire_e-recruitment_2021}
\citation{dass_detecting_2023}
\citation{gicic2023intelligent}
\citation{schaaf_towards_2021}
\citation{giloni_benn_2022}
\citation{iosifidis_fairness-enhancing_2019,kehrenberg_tuning_2020}
\citation{jain_increasing_2023}
\citation{yang_algorithmic_2023}
\citation{raiaan_systematic_2024}
\citation{pruning8794944}
\citation{Yang_CVPR}
\citation{NEURIPS2021_376c6b9f}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Technical Issues}{94}{subsection.5.2}\protected@file@percent }
\citation{ying_enhancing_2024}
\citation{wang_optimizing_2024}
\citation{yan_triple-inertial_2025}
\citation{krasnoproshin_random_2024}
\citation{adversarial2018}
\citation{szegedy2013intriguing}
\citation{tabacof2016adversarial}
\citation{zhang2020adversarial,jiang2019black,esmaeilpour2019robust}
\citation{munappy_data_2022}
\citation{luca_impact_2022}
\citation{zhuang_comprehensive_2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Domain-specific Issues}{96}{subsection.5.3}\protected@file@percent }
\citation{mumuni_data_2022}
\citation{hu_survey_2023,murtaza_synthetic_2023}
\citation{li_survey_2024}
\citation{cacciarelli_active_2024}
\citation{tan_large_2024}
\citation{gui_survey_2024}
\citation{altabrawee_stclr_2025}
\citation{altabrawee_repeat_2024}
\citation{lee_predicting_2021}
\@writefile{toc}{\contentsline {section}{\numberline {6}Summary and Future Directions}{98}{section.6}\protected@file@percent }
\newlabel{sec6}{{6}{98}{Summary and Future Directions}{section.6}{}}
\citation{dosovitskiy_image_2021}
\citation{carion_end_end_2020}
\citation{peng_conformer_2023}
\citation{tu_maxvit_2022}
\citation{devlin_bert_2018}
\citation{khan_attention_2021,ige_deep_2023}
\citation{gao_danhar_2021,agac_resource-efficient_2024,tang_triple_2022}
\citation{lupion_data_2024,kia_human_2024}
\citation{chan_unified_2021}
\citation{alamatsaz_lightweight_2024,hermawan_multi_2024}
\citation{sun_arrhythmia_2024,chen_automated_2022}
\citation{dai2019eeg}
\citation{yang_data_2024,msigwa_iot-driven_2024,song_eeggan-net_2024}
\citation{corley_deep_2025}
\citation{cai_dhct-gan_2025}
\citation{zhu_electrocardiogram_2019}
\citation{yang_data_2024}
\citation{wang_joint_2018}
\citation{zhu_bert-based_2023}
\citation{wu_study_2022,kim_towards_2023}
\citation{li_feature-aware_2023}
\citation{kwon_class_2024}
\citation{tao_df-gan_2022}
\citation{yang_dmf-gan_2024}
\citation{ma_t-bertsum_2021}
\citation{xie_pre-trained_2022}
\citation{li_incremental_2019}
\citation{wang_i_2024}
\citation{chen_synergai_2024}
\citation{allgeuer_when_2024}
\citation{asuzu_humanrobot_2025}
\citation{zhao_well-classified_2022}
\citation{huang_asymmetric_2023}
\citation{maldonado2023owadapt}
\citation{zhu2024irda}
\citation{belhaouari2024oversampling}
\citation{wang2024class}
\citation{ircio2023minimum}
\citation{moles2024exploring}
\citation{zhu2024sfpl}
\citation{jimale_subject_2023}
\citation{zhang_large_2023}
\citation{butlin_consciousness_2023}
\citation{marra_statistical_2024,colelough_neuro-symbolic_2025,bhuyan_neuro-symbolic_2024}
\citation{wu_survey_2025,klusch_quantum_2024}
\citation{shrestha_survey_2022,kudithipudi_neuromorphic_2025}
\citation{fei_towards_2022}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{104}{section.7}\protected@file@percent }
\newlabel{sec7}{{7}{104}{Conclusion}{section.7}{}}
\bibstyle{elsarticle-num}
\bibdata{elsarticle-template-num_v2}
\bibcite{shamshirband_review_2021}{{1}{}{{}}{{}}}
\bibcite{wang_deep_2018}{{2}{}{{}}{{}}}
\bibcite{pierson_deep_2017}{{3}{}{{}}{{}}}
\bibcite{dixit_deep_2021}{{4}{}{{}}{{}}}
\bibcite{noauthor_alphafold_2025}{{5}{}{{}}{{}}}
\bibcite{dong_survey_2021}{{6}{}{{}}{{}}}
\bibcite{talaei_khoei_deep_2023}{{7}{}{{}}{{}}}
\bibcite{alzubaidi_review_2021}{{8}{}{{}}{{}}}
\bibcite{alom_state_art_2019}{{9}{}{{}}{{}}}
\bibcite{pouyanfar_survey_2018}{{10}{}{{}}{{}}}
\bibcite{sarker_deep_2021}{{11}{}{{}}{{}}}
\bibcite{lecun_deep_2015}{{12}{}{{}}{{}}}
\bibcite{noauthor_poloclubcnn-explainer_2025}{{13}{}{{}}{{}}}
\bibcite{hu_squeeze-and-excitation_2019}{{14}{}{{}}{{}}}
\bibcite{gao_global_2018}{{15}{}{{}}{{}}}
\bibcite{wang_eca-net_2020}{{16}{}{{}}{{}}}
\bibcite{liu_tam_2021}{{17}{}{{}}{{}}}
\bibcite{vaswani_attention_2023}{{18}{}{{}}{{}}}
\bibcite{noauthor_poloclubtransformer-explainer_2025}{{19}{}{{}}{{}}}
\bibcite{oktay_attention_2018}{{20}{}{{}}{{}}}
\bibcite{dosovitskiy_image_2021}{{21}{}{{}}{{}}}
\bibcite{guo_beyond_2023}{{22}{}{{}}{{}}}
\bibcite{lecun_efficient_2012}{{23}{}{{}}{{}}}
\bibcite{hochreiter_gradient_2001}{{24}{}{{}}{{}}}
\bibcite{dugas_incorporating_2000}{{25}{}{{}}{{}}}
\bibcite{glorot_deep_2011}{{26}{}{{}}{{}}}
\bibcite{maas_rectifier_2013}{{27}{}{{}}{{}}}
\bibcite{misra_mish_2020}{{28}{}{{}}{{}}}
\bibcite{clevert_fast_2016}{{29}{}{{}}{{}}}
\bibcite{wang_comprehensive_2022}{{30}{}{{}}{{}}}
\bibcite{carter_tensorflow_nodate}{{31}{}{{}}{{}}}
\bibcite{guo_ai_nodate}{{32}{}{{}}{{}}}
\bibcite{qian_momentum_1999}{{33}{}{{}}{{}}}
\bibcite{duchi_adaptive_2011}{{34}{}{{}}{{}}}
\bibcite{kingma_adam_2017}{{35}{}{{}}{{}}}
\bibcite{prechelt_early_2012}{{36}{}{{}}{{}}}
\bibcite{srivastava_dropout_2014}{{37}{}{{}}{{}}}
\bibcite{park_analysis_2017}{{38}{}{{}}{{}}}
\bibcite{liu_dropout_2023}{{39}{}{{}}{{}}}
\bibcite{tibshirani_regression_1996}{{40}{}{{}}{{}}}
\bibcite{zou_regularization_2005}{{41}{}{{}}{{}}}
\bibcite{nakamura_adaptive_2019}{{42}{}{{}}{{}}}
\bibcite{ioffe_batch_2015}{{43}{}{{}}{{}}}
\bibcite{ba_layer_2016}{{44}{}{{}}{{}}}
\bibcite{cybenko_approximation_1989}{{45}{}{{}}{{}}}
\bibcite{hornik_multilayer_1989}{{46}{}{{}}{{}}}
\bibcite{widrow_neural_1994}{{47}{}{{}}{{}}}
\bibcite{hochreiter_long_1997}{{48}{}{{}}{{}}}
\bibcite{cho_learning_2014}{{49}{}{{}}{{}}}
\bibcite{shi_convolutional_2015}{{50}{}{{}}{{}}}
\bibcite{van_houdt_review_2020}{{51}{}{{}}{{}}}
\bibcite{krizhevsky_imagenet_2012}{{52}{}{{}}{{}}}
\bibcite{zeiler_visualizing_2013}{{53}{}{{}}{{}}}
\bibcite{lin_network_2014}{{54}{}{{}}{{}}}
\bibcite{simonyan_very_2015}{{55}{}{{}}{{}}}
\bibcite{szegedy_going_2014}{{56}{}{{}}{{}}}
\bibcite{srivastava_highway_2015}{{57}{}{{}}{{}}}
\bibcite{he_deep_2015}{{58}{}{{}}{{}}}
\bibcite{huang_densely_2017}{{59}{}{{}}{{}}}
\bibcite{zagoruyko_wide_2017}{{60}{}{{}}{{}}}
\bibcite{xie_aggregated_2017}{{61}{}{{}}{{}}}
\bibcite{noauthor_imagenet_nodate}{{62}{}{{}}{{}}}
\bibcite{noauthor_cifar-10_nodate}{{63}{}{{}}{{}}}
\bibcite{chougrad_deep_2018}{{64}{}{{}}{{}}}
\bibcite{zhao_novel_2020}{{65}{}{{}}{{}}}
\bibcite{cinar_hybrid_2022}{{66}{}{{}}{{}}}
\bibcite{sun_self-attentional_2023}{{67}{}{{}}{{}}}
\bibcite{dong_improved_2023}{{68}{}{{}}{{}}}
\bibcite{hou_application_2024}{{69}{}{{}}{{}}}
\bibcite{narotamo_deep_2024}{{70}{}{{}}{{}}}
\bibcite{zhang_heart_2024}{{71}{}{{}}{{}}}
\bibcite{mohd_noor_deep_2022}{{72}{}{{}}{{}}}
\bibcite{hinton_practical_2012}{{73}{}{{}}{{}}}
\bibcite{hinton_fast_2006}{{74}{}{{}}{{}}}
\bibcite{hinton_deep_2009}{{75}{}{{}}{{}}}
\bibcite{romero_quantum_2017}{{76}{}{{}}{{}}}
\bibcite{li_guided_2020}{{77}{}{{}}{{}}}
\bibcite{mohd_noor_feature_2021}{{78}{}{{}}{{}}}
\bibcite{li_comprehensive_2023}{{79}{}{{}}{{}}}
\bibcite{ng_sparse_2011}{{80}{}{{}}{{}}}
\bibcite{rifai_higher_2011}{{81}{}{{}}{{}}}
\bibcite{vincent_extracting_2008}{{82}{}{{}}{{}}}
\bibcite{chen_marginalized_2012}{{83}{}{{}}{{}}}
\bibcite{kingma_auto-encoding_2013}{{84}{}{{}}{{}}}
\bibcite{goodfellow_generative_2014}{{85}{}{{}}{{}}}
\bibcite{odena_conditional_2017}{{86}{}{{}}{{}}}
\bibcite{chen_infogan_2016}{{87}{}{{}}{{}}}
\bibcite{weng_gan_2019}{{88}{}{{}}{{}}}
\bibcite{karras_progressive_2018}{{89}{}{{}}{{}}}
\bibcite{karras_style-based_2019}{{90}{}{{}}{{}}}
\bibcite{Tan_2020_CVPR}{{91}{}{{}}{{}}}
\bibcite{Otter}{{92}{}{{}}{{}}}
\bibcite{esteva2019guide}{{93}{}{{}}{{}}}
\bibcite{soori2023artificial}{{94}{}{{}}{{}}}
\bibcite{hernandez2019systematic}{{95}{}{{}}{{}}}
\bibcite{lecun_gradient-based_1998}{{96}{}{{}}{{}}}
\bibcite{simard_best_2003}{{97}{}{{}}{{}}}
\bibcite{matsugu_subject_2003}{{98}{}{{}}{{}}}
\bibcite{zhao_well-classified_2022}{{99}{}{{}}{{}}}
\bibcite{huang_asymmetric_2023}{{100}{}{{}}{{}}}
\bibcite{park_robust_2023}{{101}{}{{}}{{}}}
\bibcite{nanni_building_2023}{{102}{}{{}}{{}}}
\bibcite{wortsman_model_2022}{{103}{}{{}}{{}}}
\bibcite{loh_multi-symmetry_2023}{{104}{}{{}}{{}}}
\bibcite{xiao_early_2021}{{105}{}{{}}{{}}}
\bibcite{wu_cvt_2021}{{106}{}{{}}{{}}}
\bibcite{peng_conformer_2023}{{107}{}{{}}{{}}}
\bibcite{tu_maxvit_2022}{{108}{}{{}}{{}}}
\bibcite{ma_convolutional_2024}{{109}{}{{}}{{}}}
\bibcite{girshick_rich_2014}{{110}{}{{}}{{}}}
\bibcite{girshick_fast_2015}{{111}{}{{}}{{}}}
\bibcite{ren_faster_2015}{{112}{}{{}}{{}}}
\bibcite{redmon_you_2016}{{113}{}{{}}{{}}}
\bibcite{redmon_yolov3_2018}{{114}{}{{}}{{}}}
\bibcite{bochkovskiy_yolov4_2020}{{115}{}{{}}{{}}}
\bibcite{liu_ssd_2016}{{116}{}{{}}{{}}}
\bibcite{lin_focal_2020}{{117}{}{{}}{{}}}
\bibcite{lin_feature_2017}{{118}{}{{}}{{}}}
\bibcite{tan_efficientdet_2020}{{119}{}{{}}{{}}}
\bibcite{tan_efficientnet_2019}{{120}{}{{}}{{}}}
\bibcite{bodla_soft-nmsimproving_2017}{{121}{}{{}}{{}}}
\bibcite{liu_adaptive_2019}{{122}{}{{}}{{}}}
\bibcite{husham_al-badri_adaptive_2023}{{123}{}{{}}{{}}}
\bibcite{jiang_non-maximum_2024}{{124}{}{{}}{{}}}
\bibcite{shi_similarity_2024}{{125}{}{{}}{{}}}
\bibcite{carion_end_end_2020}{{126}{}{{}}{{}}}
\bibcite{zhu_deformable_2020}{{127}{}{{}}{{}}}
\bibcite{dai_dynamic_2021}{{128}{}{{}}{{}}}
\bibcite{jia_detrs_2023}{{129}{}{{}}{{}}}
\bibcite{huang_teach-detr_2023}{{130}{}{{}}{{}}}
\bibcite{long_fully_2015}{{131}{}{{}}{{}}}
\bibcite{noh_learning_2015}{{132}{}{{}}{{}}}
\bibcite{badrinarayanan_segnet_2017}{{133}{}{{}}{{}}}
\bibcite{chaurasia_linknet_2017}{{134}{}{{}}{{}}}
\bibcite{he_mask_2017}{{135}{}{{}}{{}}}
\bibcite{liu_path_2018}{{136}{}{{}}{{}}}
\bibcite{chen_masklab_2018}{{137}{}{{}}{{}}}
\bibcite{liu_multi-stage_2023}{{138}{}{{}}{{}}}
\bibcite{liu_covariance_2022}{{139}{}{{}}{{}}}
\bibcite{strudel_segmenter_2021}{{140}{}{{}}{{}}}
\bibcite{hatamizadeh_global_2023}{{141}{}{{}}{{}}}
\bibcite{shi_transformer_2023}{{142}{}{{}}{{}}}
\bibcite{radford_unsupervised_2015}{{143}{}{{}}{{}}}
\bibcite{zhang_stackgan_2017}{{144}{}{{}}{{}}}
\bibcite{zhang_stackgan_2018}{{145}{}{{}}{{}}}
\bibcite{zhang_photographic_2018}{{146}{}{{}}{{}}}
\bibcite{zhu_dm-gan_2019}{{147}{}{{}}{{}}}
\bibcite{xu_attngan_2018}{{148}{}{{}}{{}}}
\bibcite{sun_resfpa-gan_2019}{{149}{}{{}}{{}}}
\bibcite{cai_dualattn-gan_2019}{{150}{}{{}}{{}}}
\bibcite{tao_df-gan_2022}{{151}{}{{}}{{}}}
\bibcite{yang_dmf-gan_2024}{{152}{}{{}}{{}}}
\bibcite{jiang_-gan_2024}{{153}{}{{}}{{}}}
\bibcite{calvo_intelligent_2000}{{154}{}{{}}{{}}}
\bibcite{yu_latent_2008}{{155}{}{{}}{{}}}
\bibcite{arevian_recurrent_2007}{{156}{}{{}}{{}}}
\bibcite{huang_optimization_2020}{{157}{}{{}}{{}}}
\bibcite{wang_convolutional_2019}{{158}{}{{}}{{}}}
\bibcite{liu_bidirectional_2019}{{159}{}{{}}{{}}}
\bibcite{lin_structured_2017}{{160}{}{{}}{{}}}
\bibcite{li_bidirectional_2020}{{161}{}{{}}{{}}}
\bibcite{devlin_bert_2018}{{162}{}{{}}{{}}}
\bibcite{lan_albert_2019}{{163}{}{{}}{{}}}
\bibcite{liu_roberta_2019}{{164}{}{{}}{{}}}
\bibcite{he_deberta_2020}{{165}{}{{}}{{}}}
\bibcite{rodrawangpai_improving_2022}{{166}{}{{}}{{}}}
\bibcite{murfi_bert-based_2024}{{167}{}{{}}{{}}}
\bibcite{hao_sentiment_2023}{{168}{}{{}}{{}}}
\bibcite{wang_joint_2018}{{169}{}{{}}{{}}}
\bibcite{yan_r-transformer_bilstm_2023}{{170}{}{{}}{{}}}
\bibcite{zhu_bert-based_2023}{{171}{}{{}}{{}}}
\bibcite{sutskever_sequence_2014}{{172}{}{{}}{{}}}
\bibcite{stahlberg_neural_2020}{{173}{}{{}}{{}}}
\bibcite{bahdanau_neural_2014}{{174}{}{{}}{{}}}
\bibcite{luong_effective_2015}{{175}{}{{}}{{}}}
\bibcite{wu_googles_2016}{{176}{}{{}}{{}}}
\bibcite{lupo_encoding_2023}{{177}{}{{}}{{}}}
\bibcite{rippeth_improving_2023}{{178}{}{{}}{{}}}
\bibcite{wu_study_2022}{{179}{}{{}}{{}}}
\bibcite{kim_towards_2023}{{180}{}{{}}{{}}}
\bibcite{gezmu_transformers_2022}{{181}{}{{}}{{}}}
\bibcite{araabi_optimizing_2020}{{182}{}{{}}{{}}}
\bibcite{meetei_cues_2023}{{183}{}{{}}{{}}}
\bibcite{faheem_improving_2024}{{184}{}{{}}{{}}}
\bibcite{li_towards_2024}{{185}{}{{}}{{}}}
\bibcite{nie_attention-based_2017}{{186}{}{{}}{{}}}
\bibcite{yin_neural_2015}{{187}{}{{}}{{}}}
\bibcite{li_deep_2016}{{188}{}{{}}{{}}}
\bibcite{wu_building_2020}{{189}{}{{}}{{}}}
\bibcite{li_incremental_2019}{{190}{}{{}}{{}}}
\bibcite{alrowili_biom-transformers_2021}{{191}{}{{}}{{}}}
\bibcite{alrowili_exploring_2022}{{192}{}{{}}{{}}}
\bibcite{ma_t-bertsum_2021}{{193}{}{{}}{{}}}
\bibcite{li_feature-aware_2023}{{194}{}{{}}{{}}}
\bibcite{kwon_class_2024}{{195}{}{{}}{{}}}
\bibcite{xie_pre-trained_2022}{{196}{}{{}}{{}}}
\bibcite{hajipoor_gptgan_2025}{{197}{}{{}}{{}}}
\bibcite{weiser1991computer}{{198}{}{{}}{{}}}
\bibcite{he2020developing}{{199}{}{{}}{{}}}
\bibcite{ige2022survey}{{200}{}{{}}{{}}}
\bibcite{singh2017stock}{{201}{}{{}}{{}}}
\bibcite{zhang2021hoba}{{202}{}{{}}{{}}}
\bibcite{lei2020deep}{{203}{}{{}}{{}}}
\bibcite{zhang2019comprehensive}{{204}{}{{}}{{}}}
\bibcite{dang2020sensor}{{205}{}{{}}{{}}}
\bibcite{gao2021danhar}{{206}{}{{}}{{}}}
\bibcite{gupta2021deep}{{207}{}{{}}{{}}}
\bibcite{erdacs2021human}{{208}{}{{}}{{}}}
\bibcite{ragab2020random}{{209}{}{{}}{{}}}
\bibcite{banjarey2022human}{{210}{}{{}}{{}}}
\bibcite{baraka_similarity_2023}{{211}{}{{}}{{}}}
\bibcite{baraka_deep_2024}{{212}{}{{}}{{}}}
\bibcite{shuvo2020hybrid}{{213}{}{{}}{{}}}
\bibcite{han2022human}{{214}{}{{}}{{}}}
\bibcite{ige2023wsense}{{215}{}{{}}{{}}}
\bibcite{deep_hybrid_2019}{{216}{}{{}}{{}}}
\bibcite{luwe_wearable_2022}{{217}{}{{}}{{}}}
\bibcite{shi_novel_2023}{{218}{}{{}}{{}}}
\bibcite{dua_inception_2023}{{219}{}{{}}{{}}}
\bibcite{imran_smart-wearable_2024}{{220}{}{{}}{{}}}
\bibcite{nafea_sensor-based_2021}{{221}{}{{}}{{}}}
\bibcite{khan_attention_2021}{{222}{}{{}}{{}}}
\bibcite{ige_deep_2023}{{223}{}{{}}{{}}}
\bibcite{gao_danhar_2021}{{224}{}{{}}{{}}}
\bibcite{agac_resource-efficient_2024}{{225}{}{{}}{{}}}
\bibcite{tang_triple_2022}{{226}{}{{}}{{}}}
\bibcite{misra_rotate_2020}{{227}{}{{}}{{}}}
\bibcite{chen_transformer_2022}{{228}{}{{}}{{}}}
\bibcite{sun_efficient_2024}{{229}{}{{}}{{}}}
\bibcite{lattanzi_are_2025}{{230}{}{{}}{{}}}
\bibcite{chan_unified_2021}{{231}{}{{}}{{}}}
\bibcite{jimale_fully_2022}{{232}{}{{}}{{}}}
\bibcite{lupion_data_2024}{{233}{}{{}}{{}}}
\bibcite{kia_human_2024}{{234}{}{{}}{{}}}
\bibcite{mohammadzadeh_cgan-based_2025}{{235}{}{{}}{{}}}
\bibcite{Nassif2019}{{236}{}{{}}{{}}}
\bibcite{Tirumala}{{237}{}{{}}{{}}}
\bibcite{app11083603}{{238}{}{{}}{{}}}
\bibcite{khalil2019}{{239}{}{{}}{{}}}
\bibcite{singh2021spoken}{{240}{}{{}}{{}}}
\bibcite{jiao2016accent}{{241}{}{{}}{{}}}
\bibcite{sanchez2022age}{{242}{}{{}}{{}}}
\bibcite{alnuaim2022speaker}{{243}{}{{}}{{}}}
\bibcite{srivastava2022speech}{{244}{}{{}}{{}}}
\bibcite{padmanabhan2015review}{{245}{}{{}}{{}}}
\bibcite{mukhamadiyev2022automatic}{{246}{}{{}}{{}}}
\bibcite{lu2020automatic}{{247}{}{{}}{{}}}
\bibcite{HEMA2023109492}{{248}{}{{}}{{}}}
\bibcite{shewalkar2019performance}{{249}{}{{}}{{}}}
\bibcite{prabhavalkar2017comparison}{{250}{}{{}}{{}}}
\bibcite{graves2012sequence}{{251}{}{{}}{{}}}
\bibcite{chan2015listen}{{252}{}{{}}{{}}}
\bibcite{jaitly2016online}{{253}{}{{}}{{}}}
\bibcite{raffel2017online}{{254}{}{{}}{{}}}
\bibcite{sak2017recurrent}{{255}{}{{}}{{}}}
\bibcite{szucbeamsearch2019}{{256}{}{{}}{{}}}
\bibcite{li2018seq2seq}{{257}{}{{}}{{}}}
\bibcite{chiugoogle}{{258}{}{{}}{{}}}
\bibcite{baevski_wav2vec_2020}{{259}{}{{}}{{}}}
\bibcite{radford_robust_2022}{{260}{}{{}}{{}}}
\bibcite{gulati_conformer_2020}{{261}{}{{}}{{}}}
\bibcite{stooke_aligner-encoders_2025}{{262}{}{{}}{{}}}
\bibcite{zhang_breaking_2025}{{263}{}{{}}{{}}}
\bibcite{wang_disentangled-transformer_2024}{{264}{}{{}}{{}}}
\bibcite{shakhadri_samba-asr_2025}{{265}{}{{}}{{}}}
\bibcite{ozbayoglu2020deep}{{266}{}{{}}{{}}}
\bibcite{shen2021new}{{267}{}{{}}{{}}}
\bibcite{wang2020portfolio}{{268}{}{{}}{{}}}
\bibcite{chen2024deep}{{269}{}{{}}{{}}}
\bibcite{ahnouch2023model}{{270}{}{{}}{{}}}
\bibcite{SUN2020101160}{{271}{}{{}}{{}}}
\bibcite{abedin2021deep}{{272}{}{{}}{{}}}
\bibcite{wang_sudf-rs_2023}{{273}{}{{}}{{}}}
\bibcite{nikou2019stock}{{274}{}{{}}{{}}}
\bibcite{cai2018financial}{{275}{}{{}}{{}}}
\bibcite{gudelek2017deep}{{276}{}{{}}{{}}}
\bibcite{eapen2019novel}{{277}{}{{}}{{}}}
\bibcite{chen_deep_2024}{{278}{}{{}}{{}}}
\bibcite{mozaffari_predictive_2024}{{279}{}{{}}{{}}}
\bibcite{li_transformer_2025}{{280}{}{{}}{{}}}
\bibcite{zhou_informer_2021}{{281}{}{{}}{{}}}
\bibcite{berti_tlob_2025}{{282}{}{{}}{{}}}
\bibcite{LIU2021107187}{{283}{}{{}}{{}}}
\bibcite{tsao2023heart}{{284}{}{{}}{{}}}
\bibcite{LLamedo2011}{{285}{}{{}}{{}}}
\bibcite{MATHEWS201853}{{286}{}{{}}{{}}}
\bibcite{zhu2019}{{287}{}{{}}{{}}}
\bibcite{desai2021low}{{288}{}{{}}{{}}}
\bibcite{crippa2015multi}{{289}{}{{}}{{}}}
\bibcite{acharya2017deep}{{290}{}{{}}{{}}}
\bibcite{baloglu2019classification}{{291}{}{{}}{{}}}
\bibcite{singh2018classification}{{292}{}{{}}{{}}}
\bibcite{prabhakararao2020attentive}{{293}{}{{}}{{}}}
\bibcite{wang2023single}{{294}{}{{}}{{}}}
\bibcite{sowmya2022contemplate}{{295}{}{{}}{{}}}
\bibcite{rai2022hybrid}{{296}{}{{}}{{}}}
\bibcite{Banerjee2020}{{297}{}{{}}{{}}}
\bibcite{kusuma_ecg_2022}{{298}{}{{}}{{}}}
\bibcite{alamatsaz_lightweight_2024}{{299}{}{{}}{{}}}
\bibcite{chen_automated_2022}{{300}{}{{}}{{}}}
\bibcite{wang_automated_2021}{{301}{}{{}}{{}}}
\bibcite{zhang_ecg-based_2020}{{302}{}{{}}{{}}}
\bibcite{sun_arrhythmia_2024}{{303}{}{{}}{{}}}
\bibcite{huang_ecg_2024}{{304}{}{{}}{{}}}
\bibcite{aghaomidi_ecg-sleepnet_2024}{{305}{}{{}}{{}}}
\bibcite{hasani_liquid_2021}{{306}{}{{}}{{}}}
\bibcite{zhu_electrocardiogram_2019}{{307}{}{{}}{{}}}
\bibcite{yang_data_2024}{{308}{}{{}}{{}}}
\bibcite{msigwa_iot-driven_2024}{{309}{}{{}}{{}}}
\bibcite{Schirrmeister2017}{{310}{}{{}}{{}}}
\bibcite{gao2021complex}{{311}{}{{}}{{}}}
\bibcite{Ang7802578}{{312}{}{{}}{{}}}
\bibcite{shen2022aberrated}{{313}{}{{}}{{}}}
\bibcite{boonyaki2020}{{314}{}{{}}{{}}}
\bibcite{sharma2021automated}{{315}{}{{}}{{}}}
\bibcite{vaquerizo2023explainable}{{316}{}{{}}{{}}}
\bibcite{modir2023systematic}{{317}{}{{}}{{}}}
\bibcite{altaheri2023deep}{{318}{}{{}}{{}}}
\bibcite{brunner2007spatial}{{319}{}{{}}{{}}}
\bibcite{delorme2007enhanced}{{320}{}{{}}{{}}}
\bibcite{jafarifarmand2019eeg}{{321}{}{{}}{{}}}
\bibcite{zhang2019novel}{{322}{}{{}}{{}}}
\bibcite{kumar2016deep}{{323}{}{{}}{{}}}
\bibcite{tibrewal2022}{{324}{}{{}}{{}}}
\bibcite{dai2019eeg}{{325}{}{{}}{{}}}
\bibcite{LiMingaiLSTM}{{326}{}{{}}{{}}}
\bibcite{Feng2020novel}{{327}{}{{}}{{}}}
\bibcite{hwang_improving_2023}{{328}{}{{}}{{}}}
\bibcite{zhao_deep_2015}{{329}{}{{}}{{}}}
\bibcite{xia_novel_2023}{{330}{}{{}}{{}}}
\bibcite{hermawan_multi_2024}{{331}{}{{}}{{}}}
\bibcite{abdulwahhab_detection_2024}{{332}{}{{}}{{}}}
\bibcite{pandey_subject_2022}{{333}{}{{}}{{}}}
\bibcite{hassouneh_development_2020}{{334}{}{{}}{{}}}
\bibcite{pan_multimodal_2024}{{335}{}{{}}{{}}}
\bibcite{wang_multimodal_2023}{{336}{}{{}}{{}}}
\bibcite{song_eeggan-net_2024}{{337}{}{{}}{{}}}
\bibcite{corley_deep_2025}{{338}{}{{}}{{}}}
\bibcite{cai_dhct-gan_2025}{{339}{}{{}}{{}}}
\bibcite{le_application_2025}{{340}{}{{}}{{}}}
\bibcite{vukicevic_versatile_2025}{{341}{}{{}}{{}}}
\bibcite{kirillov_segment_2023}{{342}{}{{}}{{}}}
\bibcite{liu_automatic_2025}{{343}{}{{}}{{}}}
\bibcite{ge_deep_2025}{{344}{}{{}}{{}}}
\bibcite{dai_advanced_2024}{{345}{}{{}}{{}}}
\bibcite{alotaibi_deep_2024}{{346}{}{{}}{{}}}
\bibcite{misir_drivable_2024}{{347}{}{{}}{{}}}
\bibcite{chen_rethinking_2017}{{348}{}{{}}{{}}}
\bibcite{cao_orchard_2024}{{349}{}{{}}{{}}}
\bibcite{liu_single-stage_2025}{{350}{}{{}}{{}}}
\bibcite{huang_survey_2025}{{351}{}{{}}{{}}}
\bibcite{asuzu_humanrobot_2025}{{352}{}{{}}{{}}}
\bibcite{chen_synergai_2024}{{353}{}{{}}{{}}}
\bibcite{allgeuer_when_2024}{{354}{}{{}}{{}}}
\bibcite{wang_i_2024}{{355}{}{{}}{{}}}
\bibcite{tonekaboni_what_2019}{{356}{}{{}}{{}}}
\bibcite{tjoa_enhancing_2023}{{357}{}{{}}{{}}}
\bibcite{li_hybrid_2024}{{358}{}{{}}{{}}}
\bibcite{termritthikun_explainable_2023}{{359}{}{{}}{{}}}
\bibcite{xiong_explainable_2022}{{360}{}{{}}{{}}}
\bibcite{fernandes_intrinsic_2023}{{361}{}{{}}{{}}}
\bibcite{freire_e-recruitment_2021}{{362}{}{{}}{{}}}
\bibcite{dass_detecting_2023}{{363}{}{{}}{{}}}
\bibcite{gicic2023intelligent}{{364}{}{{}}{{}}}
\bibcite{schaaf_towards_2021}{{365}{}{{}}{{}}}
\bibcite{giloni_benn_2022}{{366}{}{{}}{{}}}
\bibcite{iosifidis_fairness-enhancing_2019}{{367}{}{{}}{{}}}
\bibcite{kehrenberg_tuning_2020}{{368}{}{{}}{{}}}
\bibcite{jain_increasing_2023}{{369}{}{{}}{{}}}
\bibcite{yang_algorithmic_2023}{{370}{}{{}}{{}}}
\bibcite{raiaan_systematic_2024}{{371}{}{{}}{{}}}
\bibcite{pruning8794944}{{372}{}{{}}{{}}}
\bibcite{Yang_CVPR}{{373}{}{{}}{{}}}
\bibcite{NEURIPS2021_376c6b9f}{{374}{}{{}}{{}}}
\bibcite{ying_enhancing_2024}{{375}{}{{}}{{}}}
\bibcite{wang_optimizing_2024}{{376}{}{{}}{{}}}
\bibcite{yan_triple-inertial_2025}{{377}{}{{}}{{}}}
\bibcite{krasnoproshin_random_2024}{{378}{}{{}}{{}}}
\bibcite{adversarial2018}{{379}{}{{}}{{}}}
\bibcite{szegedy2013intriguing}{{380}{}{{}}{{}}}
\bibcite{tabacof2016adversarial}{{381}{}{{}}{{}}}
\bibcite{zhang2020adversarial}{{382}{}{{}}{{}}}
\bibcite{jiang2019black}{{383}{}{{}}{{}}}
\bibcite{esmaeilpour2019robust}{{384}{}{{}}{{}}}
\bibcite{munappy_data_2022}{{385}{}{{}}{{}}}
\bibcite{luca_impact_2022}{{386}{}{{}}{{}}}
\bibcite{zhuang_comprehensive_2020}{{387}{}{{}}{{}}}
\bibcite{mumuni_data_2022}{{388}{}{{}}{{}}}
\bibcite{hu_survey_2023}{{389}{}{{}}{{}}}
\bibcite{murtaza_synthetic_2023}{{390}{}{{}}{{}}}
\bibcite{li_survey_2024}{{391}{}{{}}{{}}}
\bibcite{cacciarelli_active_2024}{{392}{}{{}}{{}}}
\bibcite{tan_large_2024}{{393}{}{{}}{{}}}
\bibcite{gui_survey_2024}{{394}{}{{}}{{}}}
\bibcite{altabrawee_stclr_2025}{{395}{}{{}}{{}}}
\bibcite{altabrawee_repeat_2024}{{396}{}{{}}{{}}}
\bibcite{lee_predicting_2021}{{397}{}{{}}{{}}}
\bibcite{maldonado2023owadapt}{{398}{}{{}}{{}}}
\bibcite{zhu2024irda}{{399}{}{{}}{{}}}
\bibcite{belhaouari2024oversampling}{{400}{}{{}}{{}}}
\bibcite{wang2024class}{{401}{}{{}}{{}}}
\bibcite{ircio2023minimum}{{402}{}{{}}{{}}}
\bibcite{moles2024exploring}{{403}{}{{}}{{}}}
\bibcite{zhu2024sfpl}{{404}{}{{}}{{}}}
\bibcite{jimale_subject_2023}{{405}{}{{}}{{}}}
\bibcite{zhang_large_2023}{{406}{}{{}}{{}}}
\bibcite{butlin_consciousness_2023}{{407}{}{{}}{{}}}
\bibcite{marra_statistical_2024}{{408}{}{{}}{{}}}
\bibcite{colelough_neuro-symbolic_2025}{{409}{}{{}}{{}}}
\bibcite{bhuyan_neuro-symbolic_2024}{{410}{}{{}}{{}}}
\bibcite{wu_survey_2025}{{411}{}{{}}{{}}}
\bibcite{klusch_quantum_2024}{{412}{}{{}}{{}}}
\bibcite{shrestha_survey_2022}{{413}{}{{}}{{}}}
\bibcite{kudithipudi_neuromorphic_2025}{{414}{}{{}}{{}}}
\bibcite{fei_towards_2022}{{415}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{156}
