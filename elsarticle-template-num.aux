\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\emailauthor{halimnoor@usm.my}{Mohd Halim Mohd Noor \corref {cor1}}
\emailauthor{ayo.ige@aaua.edu.ng}{Ayokunle Olalekan Ige}
\Newlabel{cor1}{1}
\babel@aux{english}{}
\Newlabel{1}{a}
\Newlabel{2}{b}
\citation{shamshirband_review_2021}
\citation{wang_deep_2018}
\citation{pierson_deep_2017}
\citation{dixit_deep_2021}
\citation{dong_survey_2021}
\citation{talaei_khoei_deep_2023}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{sec1}{{1}{2}{Introduction}{section.1}{}}
\citation{alzubaidi_review_2021}
\citation{alom_state_art_2019}
\citation{pouyanfar_survey_2018}
\citation{sarker_deep_2021}
\citation{dong_survey_2021}
\citation{talaei_khoei_deep_2023}
\citation{alzubaidi_review_2021}
\citation{alom_state_art_2019}
\citation{pouyanfar_survey_2018}
\citation{sarker_deep_2021}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of related works.}}{4}{table.1}\protected@file@percent }
\newlabel{table_summary_related_works}{{1}{4}{Summary of related works}{table.1}{}}
\citation{lecun_deep_2015}
\@writefile{toc}{\contentsline {section}{\numberline {2}Fundamentals of Deep Learning}{5}{section.2}\protected@file@percent }
\newlabel{sec2}{{2}{5}{Fundamentals of Deep Learning}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Layers}{5}{subsection.2.1}\protected@file@percent }
\citation{lecun_deep_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A graphical representation of a neuron.}}{6}{figure.1}\protected@file@percent }
\newlabel{fig_layers_neuron}{{1}{6}{A graphical representation of a neuron}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A neuron is connected to a local region of the input data.}}{7}{figure.2}\protected@file@percent }
\newlabel{fig_layers_convolution}{{2}{7}{A neuron is connected to a local region of the input data}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Attention Mechanisms}{7}{subsection.2.2}\protected@file@percent }
\citation{hu_squeeze-and-excitation_2019}
\citation{gao_global_2018}
\citation{wang_eca-net_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Summaries of the feature map using maximum or average pooling to produce a reduced feature map.}}{8}{figure.3}\protected@file@percent }
\newlabel{fig_layers_pooling}{{3}{8}{Summaries of the feature map using maximum or average pooling to produce a reduced feature map}{figure.3}{}}
\citation{liu_tam_2021}
\citation{vaswani_attention_2023}
\citation{oktay_attention_2018}
\citation{dosovitskiy_image_2021}
\citation{guo_beyond_2023}
\citation{lecun_efficient_2012}
\citation{hochreiter_gradient_2001}
\citation{dugas_incorporating_2000}
\citation{glorot_deep_2011}
\citation{maas_rectifier_2013}
\citation{misra_mish_2020}
\citation{clevert_fast_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Activation Functions}{10}{subsection.2.3}\protected@file@percent }
\citation{wang_comprehensive_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Sigmoid activation function.}}{11}{figure.4}\protected@file@percent }
\newlabel{fig_activation_functions_sigmoid}{{4}{11}{Sigmoid activation function}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Hyperbolic tangent activation function.}}{11}{figure.5}\protected@file@percent }
\newlabel{fig_activation_functions_tanh}{{5}{11}{Hyperbolic tangent activation function}{figure.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Parameter Learning and Loss Functions}{11}{subsection.2.4}\protected@file@percent }
\citation{qian_momentum_1999}
\citation{duchi_adaptive_2011}
\citation{kingma_adam_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Rectified linear unit activation function.}}{12}{figure.6}\protected@file@percent }
\newlabel{fig_activation_functions_relu}{{6}{12}{Rectified linear unit activation function}{figure.6}{}}
\citation{prechelt_early_2012}
\citation{srivastava_dropout_2014}
\citation{srivastava_dropout_2014}
\citation{park_analysis_2017}
\citation{liu_dropout_2023}
\citation{tibshirani_regression_1996}
\citation{zou_regularization_2005}
\citation{nakamura_adaptive_2019}
\citation{ioffe_batch_2015}
\citation{ba_layer_2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Regularization Methods}{13}{subsection.2.5}\protected@file@percent }
\citation{cybenko_approximation_1989}
\citation{hornik_multilayer_1989}
\citation{widrow_neural_1994}
\citation{hochreiter_long_1997}
\citation{cho_learning_2014}
\citation{shi_convolutional_2015}
\@writefile{toc}{\contentsline {section}{\numberline {3}Types of Deep Learning}{14}{section.3}\protected@file@percent }
\newlabel{sec3}{{3}{14}{Types of Deep Learning}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Deep Supervised Learning}{14}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A fully-connected neural network.}}{15}{figure.7}\protected@file@percent }
\newlabel{fig_deep_sv_learning_mlp}{{7}{15}{A fully-connected neural network}{figure.7}{}}
\citation{krizhevsky_imagenet_2012}
\citation{simonyan_very_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A neural network with recurrent connection.}}{16}{figure.8}\protected@file@percent }
\newlabel{fig_deep_sv_learning_rnn}{{8}{16}{A neural network with recurrent connection}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A neural network with convolutional and pooling layers followed by fully-connected layers.}}{16}{figure.9}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn}{{9}{16}{A neural network with convolutional and pooling layers followed by fully-connected layers}{figure.9}{}}
\citation{zeiler_visualizing_2013}
\citation{lin_network_2014}
\citation{szegedy_going_2014}
\citation{srivastava_highway_2015}
\citation{he_deep_2015}
\citation{huang_densely_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The inception module.}}{18}{figure.10}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_inception}{{10}{18}{The inception module}{figure.10}{}}
\citation{zagoruyko_wide_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A residual connection.}}{19}{figure.11}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_resnet}{{11}{19}{A residual connection}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces A dense block.}}{19}{figure.12}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_densenet}{{12}{19}{A dense block}{figure.12}{}}
\citation{xie_aggregated_2017}
\citation{zagoruyko_wide_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A cardinal block.}}{20}{figure.13}\protected@file@percent }
\newlabel{fig_deep_sv_learning_cnn_resnext}{{13}{20}{A cardinal block}{figure.13}{}}
\citation{hinton_practical_2012}
\citation{hinton_fast_2006}
\citation{hinton_deep_2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Deep Unsupervised Learning}{21}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces A restricted Boltzmann machine.}}{21}{figure.14}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_rbm}{{14}{21}{A restricted Boltzmann machine}{figure.14}{}}
\citation{romero_quantum_2017}
\citation{li_guided_2020}
\citation{mohd_noor_feature_2021}
\citation{li_comprehensive_2023}
\citation{ng_sparse_2011}
\citation{rifai_higher_2011}
\citation{vincent_extracting_2008}
\citation{chen_marginalized_2012}
\citation{kingma_auto-encoding_2013}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces A deep belief network.}}{22}{figure.15}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_dbn}{{15}{22}{A deep belief network}{figure.15}{}}
\citation{goodfellow_generative_2014}
\citation{odena_conditional_2017}
\citation{chen_infogan_2016}
\citation{weng_gan_2019}
\citation{karras_progressive_2018}
\citation{karras_style-based_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces An autoencoder.}}{23}{figure.16}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_ae}{{16}{23}{An autoencoder}{figure.16}{}}
\citation{Tan_2020_CVPR}
\citation{Otter}
\citation{esteva2019guide}
\citation{soori2023artificial}
\citation{hernandez2019systematic}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces A generative adversarial network.}}{24}{figure.17}\protected@file@percent }
\newlabel{fig_deep_unsv_learning_gan}{{17}{24}{A generative adversarial network}{figure.17}{}}
\citation{lecun_gradient-based_1998}
\citation{simard_best_2003,matsugu_subject_2003}
\citation{krizhevsky_imagenet_2012}
\@writefile{toc}{\contentsline {section}{\numberline {4}Applications of Deep Learning}{25}{section.4}\protected@file@percent }
\newlabel{sec4}{{4}{25}{Applications of Deep Learning}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Computer Vision}{25}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Image Classification}{25}{subsubsection.4.1.1}\protected@file@percent }
\citation{zhao_well-classified_2022}
\citation{huang_asymmetric_2023}
\citation{park_robust_2023}
\citation{nanni_building_2023}
\citation{wortsman_model_2022}
\citation{loh_multi-symmetry_2023}
\citation{xiao_early_2021}
\citation{wu_cvt_2021}
\citation{peng_conformer_2023}
\citation{tu_maxvit_2022}
\citation{ma_convolutional_2024}
\citation{tu_maxvit_2022}
\citation{girshick_rich_2014}
\citation{girshick_fast_2015}
\citation{ren_faster_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The architecture of MaxViT \citep  {tu_maxvit_2022}.}}{27}{figure.18}\protected@file@percent }
\newlabel{fig_img_clf_MaxViT}{{18}{27}{The architecture of MaxViT \citep {tu_maxvit_2022}}{figure.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Object Detection}{27}{subsubsection.4.1.2}\protected@file@percent }
\citation{redmon_you_2016}
\citation{redmon_yolov3_2018}
\citation{bochkovskiy_yolov4_2020}
\citation{liu_ssd_2016}
\citation{lin_focal_2020}
\citation{lin_feature_2017}
\citation{tan_efficientdet_2020}
\citation{tan_efficientnet_2019}
\citation{bodla_soft-nmsimproving_2017}
\citation{liu_adaptive_2019}
\citation{carion_end_end_2020}
\citation{zhu_deformable_2020}
\citation{dai_dynamic_2021}
\citation{huang_teach-detr_2023}
\citation{dai_dynamic_2021}
\citation{long_fully_2015}
\citation{noh_learning_2015}
\citation{badrinarayanan_segnet_2017}
\citation{chaurasia_linknet_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The architecture of dynamic DeTR \citep  {dai_dynamic_2021}.}}{30}{figure.19}\protected@file@percent }
\newlabel{fig_obj_det_Dynamic-DETR}{{19}{30}{The architecture of dynamic DeTR \citep {dai_dynamic_2021}}{figure.19}{}}
\citation{he_mask_2017}
\citation{liu_path_2018}
\citation{chen_masklab_2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Image Segmentation}{31}{subsubsection.4.1.3}\protected@file@percent }
\citation{liu_multi-stage_2023}
\citation{liu_covariance_2022}
\citation{strudel_segmenter_2021}
\citation{hatamizadeh_global_2023}
\citation{shi_transformer_2023}
\citation{hatamizadeh_global_2023}
\citation{kingma_auto-encoding_2013}
\citation{goodfellow_generative_2014}
\citation{odena_conditional_2017}
\citation{radford_unsupervised_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces The architecture of global context ViT \citep  {hatamizadeh_global_2023}.}}{33}{figure.20}\protected@file@percent }
\newlabel{fig_img_seg_GC-ViT}{{20}{33}{The architecture of global context ViT \citep {hatamizadeh_global_2023}}{figure.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.4}Image Generation}{33}{subsubsection.4.1.4}\protected@file@percent }
\citation{zhang_stackgan_2017}
\citation{zhang_stackgan_2018}
\citation{zhang_photographic_2018}
\citation{zhu_dm-gan_2019}
\citation{xu_attngan_2018}
\citation{sun_resfpa-gan_2019}
\citation{cai_dualattn-gan_2019}
\citation{xu_attngan_2018}
\citation{tao_df-gan_2022}
\citation{yang_dmf-gan_2024}
\citation{jiang_-gan_2024}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces The architecture of AttnGAN \citep  {xu_attngan_2018}.}}{35}{figure.21}\protected@file@percent }
\newlabel{fig_image_gen_AttnGAN}{{21}{35}{The architecture of AttnGAN \citep {xu_attngan_2018}}{figure.21}{}}
\citation{yang_dmf-gan_2024}
\citation{calvo_intelligent_2000,yu_latent_2008}
\citation{arevian_recurrent_2007}
\citation{huang_optimization_2020}
\citation{wang_convolutional_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces The architecture of DMF-GAN \citep  {yang_dmf-gan_2024}.}}{36}{figure.22}\protected@file@percent }
\newlabel{fig_image_gen_DMF-GAN}{{22}{36}{The architecture of DMF-GAN \citep {yang_dmf-gan_2024}}{figure.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Natural Language Processing}{36}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Text Classification}{36}{subsubsection.4.2.1}\protected@file@percent }
\citation{liu_bidirectional_2019}
\citation{lin_structured_2017}
\citation{li_bidirectional_2020}
\citation{devlin_bert_2018}
\citation{lan_albert_2019}
\citation{liu_roberta_2019}
\citation{he_deberta_2020}
\citation{rodrawangpai_improving_2022}
\citation{murfi_bert-based_2024}
\citation{hao_sentiment_2023}
\citation{wang_joint_2018}
\citation{yan_r-transformer_bilstm_2023}
\citation{zhu_bert-based_2023}
\citation{zhu_bert-based_2023}
\citation{cho_learning_2014,sutskever_sequence_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces The architecture of BERT-MSL \citep  {zhu_bert-based_2023}.}}{39}{figure.23}\protected@file@percent }
\newlabel{fig_text_clf_BERT-MSL}{{23}{39}{The architecture of BERT-MSL \citep {zhu_bert-based_2023}}{figure.23}{}}
\citation{stahlberg_neural_2020}
\citation{bahdanau_neural_2014}
\citation{bahdanau_neural_2014}
\citation{luong_effective_2015}
\citation{vaswani_attention_2023}
\citation{luong_effective_2015}
\citation{wu_googles_2016}
\citation{vaswani_attention_2023}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Neural Machine Translation}{40}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces The architecture of an encoder-decoder \citep  {stahlberg_neural_2020}.}}{40}{figure.24}\protected@file@percent }
\newlabel{fig_nmt_encoder_decoder}{{24}{40}{The architecture of an encoder-decoder \citep {stahlberg_neural_2020}}{figure.24}{}}
\citation{wu_googles_2016}
\citation{lupo_encoding_2023}
\citation{rippeth_improving_2023}
\citation{wu_study_2022}
\citation{kim_towards_2023}
\citation{gezmu_transformers_2022}
\citation{araabi_optimizing_2020}
\citation{li_towards_2024}
\citation{meetei_cues_2023}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces The architecture of Google Neural Machine Translation \citep  {wu_googles_2016}.}}{41}{figure.25}\protected@file@percent }
\newlabel{fig_nmt_GNMT}{{25}{41}{The architecture of Google Neural Machine Translation \citep {wu_googles_2016}}{figure.25}{}}
\citation{nie_attention-based_2017}
\citation{yin_neural_2015}
\citation{li_deep_2016}
\citation{wu_building_2020}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Text Generation}{42}{subsubsection.4.2.3}\protected@file@percent }
\citation{li_incremental_2019}
\citation{alrowili_biom-transformers_2021}
\citation{alrowili_exploring_2022}
\citation{ma_t-bertsum_2021}
\citation{xie_pre-trained_2022}
\citation{weiser1991computer}
\citation{he2020developing}
\citation{ige2022survey}
\citation{mohd_noor_feature_2021}
\citation{singh2017stock}
\citation{zhang2021hoba}
\citation{lei2020deep}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Time Series and Pervasive Computing}{44}{subsection.4.3}\protected@file@percent }
\citation{zhang2019comprehensive}
\citation{ige2022survey}
\citation{dang2020sensor}
\citation{gao2021danhar}
\citation{gupta2021deep}
\citation{erdacs2021human}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Human Activity Recognition}{45}{subsubsection.4.3.1}\protected@file@percent }
\citation{mohd_noor_feature_2021}
\citation{ragab2020random}
\citation{banjarey2022human}
\citation{shuvo2020hybrid}
\citation{han2022human}
\citation{ige2023wsense}
\citation{deep2019hybrid}
\citation{luwe2022wearable,shi2023novel}
\citation{dua2023inception}
\citation{imran2023smart,chen2022transformer}
\citation{nafea2021sensor}
\citation{khan2021attention}
\citation{dlt2023110954}
\citation{khan2021attention}
\citation{Nassif2019}
\citation{Tirumala,app11083603}
\citation{khalil2019}
\citation{singh2021spoken}
\citation{jiao2016accent}
\citation{sanchez2022age}
\citation{alnuaim2022speaker}
\citation{srivastava2022speech}
\citation{padmanabhan2015review,Nassif2019}
\citation{mukhamadiyev2022automatic}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces The architecture of multi-head CNN model \citep  {khan2021attention}.}}{48}{figure.26}\protected@file@percent }
\newlabel{fig_har_multi-head_cnn}{{26}{48}{The architecture of multi-head CNN model \citep {khan2021attention}}{figure.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Speech Recognition}{48}{subsubsection.4.3.2}\protected@file@percent }
\citation{lu2020automatic}
\citation{HEMA2023109492}
\citation{shewalkar2019performance}
\citation{prabhavalkar2017comparison}
\citation{graves2012sequence}
\citation{chan2015listen}
\citation{jaitly2016online}
\citation{raffel2017online}
\citation{sak2017recurrent}
\citation{szucbeamsearch2019,li2018seq2seq}
\citation{chiugoogle}
\citation{prabhavalkar2017comparison}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Sequence-to-Sequence}}{51}{figure.27}\protected@file@percent }
\newlabel{fig_Seq_2_Seq}{{27}{51}{Sequence-to-Sequence}{figure.27}{}}
\citation{ozbayoglu2020deep}
\citation{singh2017stock}
\citation{lei2020deep}
\citation{shen2021new}
\citation{wang2020portfolio}
\citation{chen2024deep}
\citation{ahnouch2023model}
\citation{SUN2020101160}
\citation{abedin2021deep}
\citation{WANG2023119152}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Finance}{52}{subsubsection.4.3.3}\protected@file@percent }
\citation{nikou2019stock}
\citation{cai2018financial}
\citation{gudelek2017deep}
\citation{eapen2019novel}
\citation{LIU2021107187}
\citation{tsao2023heart}
\citation{LIU2021107187}
\citation{LLamedo2011}
\citation{MATHEWS201853}
\citation{zhu2019}
\citation{desai2021low}
\citation{crippa2015multi}
\citation{acharya2017deep}
\citation{baloglu2019classification}
\citation{singh2018classification}
\citation{prabhakararao2020attentive}
\citation{wang2023single}
\citation{sowmya2022contemplate}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Electrocardiogram (ECG) Classification}{54}{subsubsection.4.3.4}\protected@file@percent }
\citation{rai2022hybrid}
\citation{Banerjee2020}
\citation{kusuma2022ecg}
\citation{CHEN2022127}
\citation{wang2021automated}
\citation{zhang2020ecg}
\citation{zhu2019electrocardiogram}
\citation{Schirrmeister2017}
\citation{gao2021complex}
\citation{Schirrmeister2017}
\citation{Ang7802578}
\citation{shen2022aberrated}
\citation{boonyaki2020}
\citation{sharma2021automated,vaquerizo2023explainable}
\citation{modir2023systematic}
\citation{altaheri2023deep}
\citation{brunner2007spatial,delorme2007enhanced,jafarifarmand2019eeg}
\citation{zhang2019novel}
\citation{kumar2016deep}
\citation{tibrewal2022}
\citation{Schirrmeister2017}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.5}Electroencephalography (EEG) Classification}{57}{subsubsection.4.3.5}\protected@file@percent }
\citation{dai2019eeg}
\citation{LiMingaiLSTM}
\citation{Feng2020novel}
\citation{electronics12051186}
\citation{zhao2015deep}
\citation{xia2023novel}
\citation{hermawan2024multi}
\citation{ABDULWAHHAB2024114700}
\citation{PANDEY20221730}
\citation{hassouneh2020}
\citation{Pan2023106}
\citation{wang2023multimodal}
\citation{munappy_data_2022}
\citation{luca_impact_2022}
\citation{zhuang_comprehensive_2020}
\citation{mumuni_data_2022}
\citation{hu_survey_2023,murtaza_synthetic_2023}
\@writefile{toc}{\contentsline {section}{\numberline {5}Research Challenges}{60}{section.5}\protected@file@percent }
\newlabel{sec5}{{5}{60}{Research Challenges}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Availability and Quality}{60}{subsection.5.1}\protected@file@percent }
\citation{tonekaboni_what_2019}
\citation{tjoa_enhancing_2023}
\citation{li_hybrid_2024}
\citation{termritthikun_explainable_2023}
\citation{xiong_explainable_2022}
\citation{fernandes_intrinsic_2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Interpretability and Explainability}{61}{subsection.5.2}\protected@file@percent }
\citation{freire_e-recruitment_2021}
\citation{dass_detecting_2023}
\citation{gicic2023intelligent}
\citation{schaaf_towards_2021}
\citation{giloni_benn_2022}
\citation{iosifidis_fairness-enhancing_2019,kehrenberg_tuning_2020}
\citation{jain_increasing_2023}
\citation{yang_algorithmic_2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Ethics and Fairness}{62}{subsection.5.3}\protected@file@percent }
\citation{dlt2023110954}
\citation{pruning8794944}
\citation{Yang_CVPR}
\citation{NEURIPS2021_376c6b9f}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Lightweight Deep Learning Models}{63}{subsection.5.4}\protected@file@percent }
\citation{adversarial2018}
\citation{szegedy2013intriguing}
\citation{tabacof2016adversarial}
\citation{zhang2020adversarial,jiang2019black,esmaeilpour2019robust}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Adversarial Attack and Defense}{64}{subsection.5.5}\protected@file@percent }
\citation{dosovitskiy_image_2021}
\citation{carion_end_end_2020}
\citation{peng_conformer_2023}
\citation{tu_maxvit_2022}
\citation{devlin_bert_2018}
\citation{khan2021attention,ige2023deep}
\citation{dai2019eeg}
\citation{zhu2019electrocardiogram}
\@writefile{toc}{\contentsline {section}{\numberline {6}Summary and Future Directions}{65}{section.6}\protected@file@percent }
\newlabel{sec6}{{6}{65}{Summary and Future Directions}{section.6}{}}
\citation{wang_joint_2018}
\citation{zhu_bert-based_2023}
\citation{wu_study_2022,kim_towards_2023}
\citation{tao_df-gan_2022}
\citation{yang_dmf-gan_2024}
\citation{ma_t-bertsum_2021}
\citation{xie_pre-trained_2022}
\citation{li_incremental_2019}
\citation{zhao_well-classified_2022}
\citation{huang_asymmetric_2023}
\citation{maldonado2023owadapt}
\citation{zhu2024irda}
\citation{belhaouari2024oversampling}
\citation{wang2024class}
\citation{ircio2023minimum}
\citation{moles2024exploring}
\citation{zhu2024sfpl}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{68}{section.7}\protected@file@percent }
\newlabel{sec6}{{7}{68}{Conclusion}{section.7}{}}
\bibstyle{elsarticle-num}
\bibdata{elsarticle-template-num}
\bibcite{shamshirband_review_2021}{{1}{}{{}}{{}}}
\bibcite{wang_deep_2018}{{2}{}{{}}{{}}}
\bibcite{pierson_deep_2017}{{3}{}{{}}{{}}}
\bibcite{dixit_deep_2021}{{4}{}{{}}{{}}}
\bibcite{dong_survey_2021}{{5}{}{{}}{{}}}
\bibcite{talaei_khoei_deep_2023}{{6}{}{{}}{{}}}
\bibcite{alzubaidi_review_2021}{{7}{}{{}}{{}}}
\bibcite{alom_state_art_2019}{{8}{}{{}}{{}}}
\bibcite{pouyanfar_survey_2018}{{9}{}{{}}{{}}}
\bibcite{sarker_deep_2021}{{10}{}{{}}{{}}}
\bibcite{lecun_deep_2015}{{11}{}{{}}{{}}}
\bibcite{hu_squeeze-and-excitation_2019}{{12}{}{{}}{{}}}
\bibcite{gao_global_2018}{{13}{}{{}}{{}}}
\bibcite{wang_eca-net_2020}{{14}{}{{}}{{}}}
\bibcite{liu_tam_2021}{{15}{}{{}}{{}}}
\bibcite{vaswani_attention_2023}{{16}{}{{}}{{}}}
\bibcite{oktay_attention_2018}{{17}{}{{}}{{}}}
\bibcite{dosovitskiy_image_2021}{{18}{}{{}}{{}}}
\bibcite{guo_beyond_2023}{{19}{}{{}}{{}}}
\bibcite{lecun_efficient_2012}{{20}{}{{}}{{}}}
\bibcite{hochreiter_gradient_2001}{{21}{}{{}}{{}}}
\bibcite{dugas_incorporating_2000}{{22}{}{{}}{{}}}
\bibcite{glorot_deep_2011}{{23}{}{{}}{{}}}
\bibcite{maas_rectifier_2013}{{24}{}{{}}{{}}}
\bibcite{misra_mish_2020}{{25}{}{{}}{{}}}
\bibcite{clevert_fast_2016}{{26}{}{{}}{{}}}
\bibcite{wang_comprehensive_2022}{{27}{}{{}}{{}}}
\bibcite{qian_momentum_1999}{{28}{}{{}}{{}}}
\bibcite{duchi_adaptive_2011}{{29}{}{{}}{{}}}
\bibcite{kingma_adam_2017}{{30}{}{{}}{{}}}
\bibcite{prechelt_early_2012}{{31}{}{{}}{{}}}
\bibcite{srivastava_dropout_2014}{{32}{}{{}}{{}}}
\bibcite{park_analysis_2017}{{33}{}{{}}{{}}}
\bibcite{liu_dropout_2023}{{34}{}{{}}{{}}}
\bibcite{tibshirani_regression_1996}{{35}{}{{}}{{}}}
\bibcite{zou_regularization_2005}{{36}{}{{}}{{}}}
\bibcite{nakamura_adaptive_2019}{{37}{}{{}}{{}}}
\bibcite{ioffe_batch_2015}{{38}{}{{}}{{}}}
\bibcite{ba_layer_2016}{{39}{}{{}}{{}}}
\bibcite{cybenko_approximation_1989}{{40}{}{{}}{{}}}
\bibcite{hornik_multilayer_1989}{{41}{}{{}}{{}}}
\bibcite{widrow_neural_1994}{{42}{}{{}}{{}}}
\bibcite{hochreiter_long_1997}{{43}{}{{}}{{}}}
\bibcite{cho_learning_2014}{{44}{}{{}}{{}}}
\bibcite{shi_convolutional_2015}{{45}{}{{}}{{}}}
\bibcite{krizhevsky_imagenet_2012}{{46}{}{{}}{{}}}
\bibcite{simonyan_very_2015}{{47}{}{{}}{{}}}
\bibcite{zeiler_visualizing_2013}{{48}{}{{}}{{}}}
\bibcite{lin_network_2014}{{49}{}{{}}{{}}}
\bibcite{szegedy_going_2014}{{50}{}{{}}{{}}}
\bibcite{srivastava_highway_2015}{{51}{}{{}}{{}}}
\bibcite{he_deep_2015}{{52}{}{{}}{{}}}
\bibcite{huang_densely_2017}{{53}{}{{}}{{}}}
\bibcite{zagoruyko_wide_2017}{{54}{}{{}}{{}}}
\bibcite{xie_aggregated_2017}{{55}{}{{}}{{}}}
\bibcite{hinton_practical_2012}{{56}{}{{}}{{}}}
\bibcite{hinton_fast_2006}{{57}{}{{}}{{}}}
\bibcite{hinton_deep_2009}{{58}{}{{}}{{}}}
\bibcite{romero_quantum_2017}{{59}{}{{}}{{}}}
\bibcite{li_guided_2020}{{60}{}{{}}{{}}}
\bibcite{mohd_noor_feature_2021}{{61}{}{{}}{{}}}
\bibcite{li_comprehensive_2023}{{62}{}{{}}{{}}}
\bibcite{ng_sparse_2011}{{63}{}{{}}{{}}}
\bibcite{rifai_higher_2011}{{64}{}{{}}{{}}}
\bibcite{vincent_extracting_2008}{{65}{}{{}}{{}}}
\bibcite{chen_marginalized_2012}{{66}{}{{}}{{}}}
\bibcite{kingma_auto-encoding_2013}{{67}{}{{}}{{}}}
\bibcite{goodfellow_generative_2014}{{68}{}{{}}{{}}}
\bibcite{odena_conditional_2017}{{69}{}{{}}{{}}}
\bibcite{chen_infogan_2016}{{70}{}{{}}{{}}}
\bibcite{weng_gan_2019}{{71}{}{{}}{{}}}
\bibcite{karras_progressive_2018}{{72}{}{{}}{{}}}
\bibcite{karras_style-based_2019}{{73}{}{{}}{{}}}
\bibcite{Tan_2020_CVPR}{{74}{}{{}}{{}}}
\bibcite{Otter}{{75}{}{{}}{{}}}
\bibcite{esteva2019guide}{{76}{}{{}}{{}}}
\bibcite{soori2023artificial}{{77}{}{{}}{{}}}
\bibcite{hernandez2019systematic}{{78}{}{{}}{{}}}
\bibcite{lecun_gradient-based_1998}{{79}{}{{}}{{}}}
\bibcite{simard_best_2003}{{80}{}{{}}{{}}}
\bibcite{matsugu_subject_2003}{{81}{}{{}}{{}}}
\bibcite{zhao_well-classified_2022}{{82}{}{{}}{{}}}
\bibcite{huang_asymmetric_2023}{{83}{}{{}}{{}}}
\bibcite{park_robust_2023}{{84}{}{{}}{{}}}
\bibcite{nanni_building_2023}{{85}{}{{}}{{}}}
\bibcite{wortsman_model_2022}{{86}{}{{}}{{}}}
\bibcite{loh_multi-symmetry_2023}{{87}{}{{}}{{}}}
\bibcite{xiao_early_2021}{{88}{}{{}}{{}}}
\bibcite{wu_cvt_2021}{{89}{}{{}}{{}}}
\bibcite{peng_conformer_2023}{{90}{}{{}}{{}}}
\bibcite{tu_maxvit_2022}{{91}{}{{}}{{}}}
\bibcite{ma_convolutional_2024}{{92}{}{{}}{{}}}
\bibcite{girshick_rich_2014}{{93}{}{{}}{{}}}
\bibcite{girshick_fast_2015}{{94}{}{{}}{{}}}
\bibcite{ren_faster_2015}{{95}{}{{}}{{}}}
\bibcite{redmon_you_2016}{{96}{}{{}}{{}}}
\bibcite{redmon_yolov3_2018}{{97}{}{{}}{{}}}
\bibcite{bochkovskiy_yolov4_2020}{{98}{}{{}}{{}}}
\bibcite{liu_ssd_2016}{{99}{}{{}}{{}}}
\bibcite{lin_focal_2020}{{100}{}{{}}{{}}}
\bibcite{lin_feature_2017}{{101}{}{{}}{{}}}
\bibcite{tan_efficientdet_2020}{{102}{}{{}}{{}}}
\bibcite{tan_efficientnet_2019}{{103}{}{{}}{{}}}
\bibcite{bodla_soft-nmsimproving_2017}{{104}{}{{}}{{}}}
\bibcite{liu_adaptive_2019}{{105}{}{{}}{{}}}
\bibcite{carion_end_end_2020}{{106}{}{{}}{{}}}
\bibcite{zhu_deformable_2020}{{107}{}{{}}{{}}}
\bibcite{dai_dynamic_2021}{{108}{}{{}}{{}}}
\bibcite{huang_teach-detr_2023}{{109}{}{{}}{{}}}
\bibcite{long_fully_2015}{{110}{}{{}}{{}}}
\bibcite{noh_learning_2015}{{111}{}{{}}{{}}}
\bibcite{badrinarayanan_segnet_2017}{{112}{}{{}}{{}}}
\bibcite{chaurasia_linknet_2017}{{113}{}{{}}{{}}}
\bibcite{he_mask_2017}{{114}{}{{}}{{}}}
\bibcite{liu_path_2018}{{115}{}{{}}{{}}}
\bibcite{chen_masklab_2018}{{116}{}{{}}{{}}}
\bibcite{liu_multi-stage_2023}{{117}{}{{}}{{}}}
\bibcite{liu_covariance_2022}{{118}{}{{}}{{}}}
\bibcite{strudel_segmenter_2021}{{119}{}{{}}{{}}}
\bibcite{hatamizadeh_global_2023}{{120}{}{{}}{{}}}
\bibcite{shi_transformer_2023}{{121}{}{{}}{{}}}
\bibcite{radford_unsupervised_2015}{{122}{}{{}}{{}}}
\bibcite{zhang_stackgan_2017}{{123}{}{{}}{{}}}
\bibcite{zhang_stackgan_2018}{{124}{}{{}}{{}}}
\bibcite{zhang_photographic_2018}{{125}{}{{}}{{}}}
\bibcite{zhu_dm-gan_2019}{{126}{}{{}}{{}}}
\bibcite{xu_attngan_2018}{{127}{}{{}}{{}}}
\bibcite{sun_resfpa-gan_2019}{{128}{}{{}}{{}}}
\bibcite{cai_dualattn-gan_2019}{{129}{}{{}}{{}}}
\bibcite{tao_df-gan_2022}{{130}{}{{}}{{}}}
\bibcite{yang_dmf-gan_2024}{{131}{}{{}}{{}}}
\bibcite{jiang_-gan_2024}{{132}{}{{}}{{}}}
\bibcite{calvo_intelligent_2000}{{133}{}{{}}{{}}}
\bibcite{yu_latent_2008}{{134}{}{{}}{{}}}
\bibcite{arevian_recurrent_2007}{{135}{}{{}}{{}}}
\bibcite{huang_optimization_2020}{{136}{}{{}}{{}}}
\bibcite{wang_convolutional_2019}{{137}{}{{}}{{}}}
\bibcite{liu_bidirectional_2019}{{138}{}{{}}{{}}}
\bibcite{lin_structured_2017}{{139}{}{{}}{{}}}
\bibcite{li_bidirectional_2020}{{140}{}{{}}{{}}}
\bibcite{devlin_bert_2018}{{141}{}{{}}{{}}}
\bibcite{lan_albert_2019}{{142}{}{{}}{{}}}
\bibcite{liu_roberta_2019}{{143}{}{{}}{{}}}
\bibcite{he_deberta_2020}{{144}{}{{}}{{}}}
\bibcite{rodrawangpai_improving_2022}{{145}{}{{}}{{}}}
\bibcite{murfi_bert-based_2024}{{146}{}{{}}{{}}}
\bibcite{hao_sentiment_2023}{{147}{}{{}}{{}}}
\bibcite{wang_joint_2018}{{148}{}{{}}{{}}}
\bibcite{yan_r-transformer_bilstm_2023}{{149}{}{{}}{{}}}
\bibcite{zhu_bert-based_2023}{{150}{}{{}}{{}}}
\bibcite{sutskever_sequence_2014}{{151}{}{{}}{{}}}
\bibcite{stahlberg_neural_2020}{{152}{}{{}}{{}}}
\bibcite{bahdanau_neural_2014}{{153}{}{{}}{{}}}
\bibcite{luong_effective_2015}{{154}{}{{}}{{}}}
\bibcite{wu_googles_2016}{{155}{}{{}}{{}}}
\bibcite{lupo_encoding_2023}{{156}{}{{}}{{}}}
\bibcite{rippeth_improving_2023}{{157}{}{{}}{{}}}
\bibcite{wu_study_2022}{{158}{}{{}}{{}}}
\bibcite{kim_towards_2023}{{159}{}{{}}{{}}}
\bibcite{gezmu_transformers_2022}{{160}{}{{}}{{}}}
\bibcite{araabi_optimizing_2020}{{161}{}{{}}{{}}}
\bibcite{li_towards_2024}{{162}{}{{}}{{}}}
\bibcite{meetei_cues_2023}{{163}{}{{}}{{}}}
\bibcite{nie_attention-based_2017}{{164}{}{{}}{{}}}
\bibcite{yin_neural_2015}{{165}{}{{}}{{}}}
\bibcite{li_deep_2016}{{166}{}{{}}{{}}}
\bibcite{wu_building_2020}{{167}{}{{}}{{}}}
\bibcite{li_incremental_2019}{{168}{}{{}}{{}}}
\bibcite{alrowili_biom-transformers_2021}{{169}{}{{}}{{}}}
\bibcite{alrowili_exploring_2022}{{170}{}{{}}{{}}}
\bibcite{ma_t-bertsum_2021}{{171}{}{{}}{{}}}
\bibcite{xie_pre-trained_2022}{{172}{}{{}}{{}}}
\bibcite{weiser1991computer}{{173}{}{{}}{{}}}
\bibcite{he2020developing}{{174}{}{{}}{{}}}
\bibcite{ige2022survey}{{175}{}{{}}{{}}}
\bibcite{singh2017stock}{{176}{}{{}}{{}}}
\bibcite{zhang2021hoba}{{177}{}{{}}{{}}}
\bibcite{lei2020deep}{{178}{}{{}}{{}}}
\bibcite{zhang2019comprehensive}{{179}{}{{}}{{}}}
\bibcite{dang2020sensor}{{180}{}{{}}{{}}}
\bibcite{gao2021danhar}{{181}{}{{}}{{}}}
\bibcite{gupta2021deep}{{182}{}{{}}{{}}}
\bibcite{erdacs2021human}{{183}{}{{}}{{}}}
\bibcite{ragab2020random}{{184}{}{{}}{{}}}
\bibcite{banjarey2022human}{{185}{}{{}}{{}}}
\bibcite{shuvo2020hybrid}{{186}{}{{}}{{}}}
\bibcite{han2022human}{{187}{}{{}}{{}}}
\bibcite{ige2023wsense}{{188}{}{{}}{{}}}
\bibcite{deep2019hybrid}{{189}{}{{}}{{}}}
\bibcite{luwe2022wearable}{{190}{}{{}}{{}}}
\bibcite{shi2023novel}{{191}{}{{}}{{}}}
\bibcite{dua2023inception}{{192}{}{{}}{{}}}
\bibcite{imran2023smart}{{193}{}{{}}{{}}}
\bibcite{chen2022transformer}{{194}{}{{}}{{}}}
\bibcite{nafea2021sensor}{{195}{}{{}}{{}}}
\bibcite{khan2021attention}{{196}{}{{}}{{}}}
\bibcite{dlt2023110954}{{197}{}{{}}{{}}}
\bibcite{Nassif2019}{{198}{}{{}}{{}}}
\bibcite{Tirumala}{{199}{}{{}}{{}}}
\bibcite{app11083603}{{200}{}{{}}{{}}}
\bibcite{khalil2019}{{201}{}{{}}{{}}}
\bibcite{singh2021spoken}{{202}{}{{}}{{}}}
\bibcite{jiao2016accent}{{203}{}{{}}{{}}}
\bibcite{sanchez2022age}{{204}{}{{}}{{}}}
\bibcite{alnuaim2022speaker}{{205}{}{{}}{{}}}
\bibcite{srivastava2022speech}{{206}{}{{}}{{}}}
\bibcite{padmanabhan2015review}{{207}{}{{}}{{}}}
\bibcite{mukhamadiyev2022automatic}{{208}{}{{}}{{}}}
\bibcite{lu2020automatic}{{209}{}{{}}{{}}}
\bibcite{HEMA2023109492}{{210}{}{{}}{{}}}
\bibcite{shewalkar2019performance}{{211}{}{{}}{{}}}
\bibcite{prabhavalkar2017comparison}{{212}{}{{}}{{}}}
\bibcite{graves2012sequence}{{213}{}{{}}{{}}}
\bibcite{chan2015listen}{{214}{}{{}}{{}}}
\bibcite{jaitly2016online}{{215}{}{{}}{{}}}
\bibcite{raffel2017online}{{216}{}{{}}{{}}}
\bibcite{sak2017recurrent}{{217}{}{{}}{{}}}
\bibcite{szucbeamsearch2019}{{218}{}{{}}{{}}}
\bibcite{li2018seq2seq}{{219}{}{{}}{{}}}
\bibcite{chiugoogle}{{220}{}{{}}{{}}}
\bibcite{ozbayoglu2020deep}{{221}{}{{}}{{}}}
\bibcite{shen2021new}{{222}{}{{}}{{}}}
\bibcite{wang2020portfolio}{{223}{}{{}}{{}}}
\bibcite{chen2024deep}{{224}{}{{}}{{}}}
\bibcite{ahnouch2023model}{{225}{}{{}}{{}}}
\bibcite{SUN2020101160}{{226}{}{{}}{{}}}
\bibcite{abedin2021deep}{{227}{}{{}}{{}}}
\bibcite{WANG2023119152}{{228}{}{{}}{{}}}
\bibcite{nikou2019stock}{{229}{}{{}}{{}}}
\bibcite{cai2018financial}{{230}{}{{}}{{}}}
\bibcite{gudelek2017deep}{{231}{}{{}}{{}}}
\bibcite{eapen2019novel}{{232}{}{{}}{{}}}
\bibcite{LIU2021107187}{{233}{}{{}}{{}}}
\bibcite{tsao2023heart}{{234}{}{{}}{{}}}
\bibcite{LLamedo2011}{{235}{}{{}}{{}}}
\bibcite{MATHEWS201853}{{236}{}{{}}{{}}}
\bibcite{zhu2019}{{237}{}{{}}{{}}}
\bibcite{desai2021low}{{238}{}{{}}{{}}}
\bibcite{crippa2015multi}{{239}{}{{}}{{}}}
\bibcite{acharya2017deep}{{240}{}{{}}{{}}}
\bibcite{baloglu2019classification}{{241}{}{{}}{{}}}
\bibcite{singh2018classification}{{242}{}{{}}{{}}}
\bibcite{prabhakararao2020attentive}{{243}{}{{}}{{}}}
\bibcite{wang2023single}{{244}{}{{}}{{}}}
\bibcite{sowmya2022contemplate}{{245}{}{{}}{{}}}
\bibcite{rai2022hybrid}{{246}{}{{}}{{}}}
\bibcite{Banerjee2020}{{247}{}{{}}{{}}}
\bibcite{kusuma2022ecg}{{248}{}{{}}{{}}}
\bibcite{CHEN2022127}{{249}{}{{}}{{}}}
\bibcite{wang2021automated}{{250}{}{{}}{{}}}
\bibcite{zhang2020ecg}{{251}{}{{}}{{}}}
\bibcite{zhu2019electrocardiogram}{{252}{}{{}}{{}}}
\bibcite{Schirrmeister2017}{{253}{}{{}}{{}}}
\bibcite{gao2021complex}{{254}{}{{}}{{}}}
\bibcite{Ang7802578}{{255}{}{{}}{{}}}
\bibcite{shen2022aberrated}{{256}{}{{}}{{}}}
\bibcite{boonyaki2020}{{257}{}{{}}{{}}}
\bibcite{sharma2021automated}{{258}{}{{}}{{}}}
\bibcite{vaquerizo2023explainable}{{259}{}{{}}{{}}}
\bibcite{modir2023systematic}{{260}{}{{}}{{}}}
\bibcite{altaheri2023deep}{{261}{}{{}}{{}}}
\bibcite{brunner2007spatial}{{262}{}{{}}{{}}}
\bibcite{delorme2007enhanced}{{263}{}{{}}{{}}}
\bibcite{jafarifarmand2019eeg}{{264}{}{{}}{{}}}
\bibcite{zhang2019novel}{{265}{}{{}}{{}}}
\bibcite{kumar2016deep}{{266}{}{{}}{{}}}
\bibcite{tibrewal2022}{{267}{}{{}}{{}}}
\bibcite{dai2019eeg}{{268}{}{{}}{{}}}
\bibcite{LiMingaiLSTM}{{269}{}{{}}{{}}}
\bibcite{Feng2020novel}{{270}{}{{}}{{}}}
\bibcite{electronics12051186}{{271}{}{{}}{{}}}
\bibcite{zhao2015deep}{{272}{}{{}}{{}}}
\bibcite{xia2023novel}{{273}{}{{}}{{}}}
\bibcite{hermawan2024multi}{{274}{}{{}}{{}}}
\bibcite{ABDULWAHHAB2024114700}{{275}{}{{}}{{}}}
\bibcite{PANDEY20221730}{{276}{}{{}}{{}}}
\bibcite{hassouneh2020}{{277}{}{{}}{{}}}
\bibcite{Pan2023106}{{278}{}{{}}{{}}}
\bibcite{wang2023multimodal}{{279}{}{{}}{{}}}
\bibcite{munappy_data_2022}{{280}{}{{}}{{}}}
\bibcite{luca_impact_2022}{{281}{}{{}}{{}}}
\bibcite{zhuang_comprehensive_2020}{{282}{}{{}}{{}}}
\bibcite{mumuni_data_2022}{{283}{}{{}}{{}}}
\bibcite{hu_survey_2023}{{284}{}{{}}{{}}}
\bibcite{murtaza_synthetic_2023}{{285}{}{{}}{{}}}
\bibcite{tonekaboni_what_2019}{{286}{}{{}}{{}}}
\bibcite{tjoa_enhancing_2023}{{287}{}{{}}{{}}}
\bibcite{li_hybrid_2024}{{288}{}{{}}{{}}}
\bibcite{termritthikun_explainable_2023}{{289}{}{{}}{{}}}
\bibcite{xiong_explainable_2022}{{290}{}{{}}{{}}}
\bibcite{fernandes_intrinsic_2023}{{291}{}{{}}{{}}}
\bibcite{freire_e-recruitment_2021}{{292}{}{{}}{{}}}
\bibcite{dass_detecting_2023}{{293}{}{{}}{{}}}
\bibcite{gicic2023intelligent}{{294}{}{{}}{{}}}
\bibcite{schaaf_towards_2021}{{295}{}{{}}{{}}}
\bibcite{giloni_benn_2022}{{296}{}{{}}{{}}}
\bibcite{iosifidis_fairness-enhancing_2019}{{297}{}{{}}{{}}}
\bibcite{kehrenberg_tuning_2020}{{298}{}{{}}{{}}}
\bibcite{jain_increasing_2023}{{299}{}{{}}{{}}}
\bibcite{yang_algorithmic_2023}{{300}{}{{}}{{}}}
\bibcite{pruning8794944}{{301}{}{{}}{{}}}
\bibcite{Yang_CVPR}{{302}{}{{}}{{}}}
\bibcite{NEURIPS2021_376c6b9f}{{303}{}{{}}{{}}}
\bibcite{adversarial2018}{{304}{}{{}}{{}}}
\bibcite{szegedy2013intriguing}{{305}{}{{}}{{}}}
\bibcite{tabacof2016adversarial}{{306}{}{{}}{{}}}
\bibcite{zhang2020adversarial}{{307}{}{{}}{{}}}
\bibcite{jiang2019black}{{308}{}{{}}{{}}}
\bibcite{esmaeilpour2019robust}{{309}{}{{}}{{}}}
\bibcite{maldonado2023owadapt}{{310}{}{{}}{{}}}
\bibcite{zhu2024irda}{{311}{}{{}}{{}}}
\bibcite{belhaouari2024oversampling}{{312}{}{{}}{{}}}
\bibcite{wang2024class}{{313}{}{{}}{{}}}
\bibcite{ircio2023minimum}{{314}{}{{}}{{}}}
\bibcite{moles2024exploring}{{315}{}{{}}{{}}}
\bibcite{zhu2024sfpl}{{316}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\gdef \@abspage@last{105}
